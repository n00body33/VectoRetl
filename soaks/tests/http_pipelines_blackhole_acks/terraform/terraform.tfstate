{
  "version": 4,
  "terraform_version": "1.0.11",
  "serial": 24,
  "lineage": "174eb4eb-b22b-14ea-25cb-80e5425fcf2d",
  "outputs": {},
  "resources": [
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "soak",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "soak",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "soak",
                "resource_version": "448",
                "uid": "253a585b-28b0-4511-86e7-d1ef3caceac5"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "module": "module.http-gen",
      "mode": "managed",
      "type": "kubernetes_config_map",
      "name": "lading",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "binary_data": null,
            "data": {
              "http_gen.yaml": "worker_threads: 1\nprometheus_addr: \"0.0.0.0:9090\"\n\ntargets:\n  vector:\n    headers: {}\n    target_uri: \"http://vector:8282/\"\n    bytes_per_second: \"500 Mb\"\n    parallel_connections: 10\n    method:\n      post:\n        maximum_prebuild_cache_size_bytes: \"256 Mb\"\n        variant:\n          static:\n            static_path: \"/data/bootstrap.log\"\n"
            },
            "id": "soak/lading-http-gen",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "lading-http-gen",
                "namespace": "soak",
                "resource_version": "524",
                "uid": "4cdddc9f-4627-4fd4-9297-cd4f04f9a375"
              }
            ]
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kubernetes_namespace.soak",
            "module.vector.kubernetes_config_map.vector",
            "module.vector.kubernetes_deployment.vector",
            "module.vector.kubernetes_service.vector"
          ]
        }
      ]
    },
    {
      "module": "module.http-gen",
      "mode": "managed",
      "type": "kubernetes_config_map",
      "name": "lading_bootstrap",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "binary_data": null,
            "data": {
              "bootstrap.log": "{ \"source\" : \"nginx\", \"message\": \"127.0.0.1 - frank [13\\/Jul\\/2016:10:55:36 +0000] \\\"GET \\/apache_pb.gif HTTP\\/1.0\\\" 200 2326\" }\n{ \"source\" : \"nginx\", \"message\": \"172.17.0.1 - - [06\\/Jan\\/2017:16:16:37 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 404 612 \\\"http:\\/\\/www.perdu.com\\/\\\" \\\"Mozilla\\/5.0 (X11; Linux x86_64) AppleWebKit\\/537.36 (KHTML, like Gecko) Chrome\\/55.0.2883.87 Safari\\/537.36\\\" \\\"-\\\"\" }\n{ \"source\" : \"nginx\", \"message\": \"172.17.0.1 - - [06\\/Jan\\/2017:16:16:37 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 200 612 \\\"http:\\/\\/www.perdu.com\\/\\\" \\\"Mozilla\\/5.0 (X11; Linux x86_64) AppleWebKit\\/537.36 (KHTML, like Gecko) Chrome\\/55.0.2883.87 Safari\\/537.36\\\" \\\"-\\\" those are random characters\" }\n{ \"source\" : \"nginx\", \"message\": \"2017\\/09\\/26 14:36:50 [error] 8409#8409: *317058 \\\"\\/usr\\/share\\/nginx\\/html\\/sql\\/sql-admin\\/index.html\\\" is not found (2: No such file or directory), client: 217.92.148.44, server: localhost, request: \\\"HEAD http:\\/\\/174.138.82.103:80\\/sql\\/sql-admin\\/ HTTP\\/1.1\\\", host: \\\"174.138.82.103\\\"\" }\n{ \"source\" : \"nginx\", \"message\": \"2017\\/09\\/26 14:36:50 [info] 14#14: *285 client 172.17.0.27 closed keepalive connection\" }\n{ \"source\" : \"nginx\", \"message\": \"127.0.0.1 - - [19\\/Feb\\/2015:15:50:36 -0500] \\\"GET \\/big.pdf HTTP\\/1.1\\\" 206 33973115 0.202 \\\"-\\\" \\\"Mozilla\\/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit\\/537.36 (KHTML, like Gecko) Chrome\\/40.0.2214.111 Safari\\/537.36\\\"\" }\n{ \"source\" : \"redis\", \"message\": \"12115:M 08 Jan 17:45:41.572 # WARNING: The TCP backlog setting of 511 cannot be enforced because \\/proc\\/sys\\/net\\/core\\/somaxconn is set to the lower value of 128.\" }\n{ \"source\" : \"redis\", \"message\": \"12115:M 08 Jan 17:45:41.572 # Server started, Redis version 3.0.6\" }\n{ \"source\" : \"redis\", \"message\": \"3575:M 16 Apr 15:37:05.124 - DB 0: 1 keys (0 volatile) in 4 slots HT.\" }\n{ \"source\" : \"redis\", \"message\": \"1:M 14 May 2019 19:11:40.164 * Background saving terminated with success\" }\n{ \"source\" : \"consul\", \"message\": \"==\u003e WARNING: It is highly recommended to set GOMAXPROCS higher than 1\" }\n{ \"source\" : \"consul\", \"message\": \"\\t2015\\/11\\/24 11:41:05 [INFO] serf: EventMemberJoin: 10.0.255.5 10.0.255.5\" }\n{ \"source\" : \"consul\", \"message\": \"Mar 23 14:39:46 precise64 consul-template[23544]: (runner) creating Watcher\" }\n{ \"source\" : \"consul\", \"message\": \"2018-10-19T19:04:16.180Z [TRACE] pkcs11: key successfully found\" }\n{ \"source\" : \"python\", \"message\": \"{\\\"threadName\\\": \\\"MainThread\\\",\\\"name\\\": \\\"root\\\",\\\"thread\\\": 140735202359648,\\\"created\\\": 1336281068.506248,\\\"process\\\": 41937,\\\"processName\\\": \\\"MainProcess\\\",\\\"relativeCreated\\\": 9.100914001464844,\\\"module\\\": \\\"tests\\\",\\\"funcName\\\": \\\"testFormatKeys\\\",\\\"levelno\\\": 20,\\\"msecs\\\": 506.24799728393555,\\\"pathname\\\": \\\"tests\\/tests.py\\\",\\\"lineno\\\": 60,\\\"asctime\\\": [\\\"12-05-05 22:11:08,506248\\\"],\\\"message\\\": \\\"testing logging format\\\",\\\"filename\\\": \\\"tests.py\\\",\\\"levelname\\\": \\\"INFO\\\",\\\"special\\\": \\\"value\\\",\\t\\\"run\\\": 12}\" }\n{ \"source\" : \"python\", \"message\": \"2017-12-26T10:44:59,311 ERROR [dd.dogweb.lib.static_asset] [20081] rid=b0RV4J Error reading statics_version file.Traceback (most recent call last): File \\\"\\/home\\/vagrant\\/dogweb\\/dogweb\\/lib\\/static_asset.py\\\", line 16, in version    with open(\\\"\\/etc\\/datadog\\/statics_version.txt\\\", \\\"r\\\") as statics_version_file: IOError: [Errno 2] No such file or directory: \\/etc\\/datadog\\/statics_version.txt\" }\n{ \"source\" : \"python\", \"message\": \"2017-12-26T10:44:59,311 ERROR Error reading statics_version file.\" }\n{ \"source\" : \"python\", \"message\": \"2019-01-07 15:20:15,972 DEBUG [flask.app] [app.py:100] [dd.trace_id=5688176451479556031 dd.span_id=4663104081780224235] - Hook: teardown_appcontext\" }\n{ \"source\" : \"python\", \"message\": \"2019-01-07 15:20:15,972 DEBUG [flask.app] [app.py:100] [dd.trace_id=5688176451479556031 dd.span_id=4663104081780224235] - rid=b0RV4J Error reading statics_version file.Traceback (most recent call last): File \\\"\\/home\\/vagrant\\/dogweb\\/dogweb\\/lib\\/static_asset.py\\\", line 16, in version    with open(\\\"\\/etc\\/datadog\\/statics_version.txt\\\", \\\"r\\\") as statics_version_file: IOError: [Errno 2] No such file or directory: \\/etc\\/datadog\\/statics_version.txt\" }\n{ \"source\" : \"python\", \"message\": \"2020-03-20 14:15:07,124 INFO [root] [app.py:78] [dd.service=excelsior dd.env=jesse-dev dd.version=abc123 dd.trace_id=9659687005038611690 dd.span_id=6632586210846541907] - This is a test of info logs\" }\n{ \"source\" : \"rabbitmq\", \"message\": \"=INFO REPORT==== 8-Mar-2018::14:09:27 === closing AMQP connection \u003c0.22578.1180\u003e (62.210.247.209:43887 -\u003e 62.210.129.60:5672\" }\n{ \"source\" : \"rabbitmq\", \"message\": \"2018-11-22 10:44:33.654 [info] \u003c0.620.0\u003e accepting AMQP connection \u003c0.620.0\u003e (127.0.0.1:52771 -\u003e 127.0.0.1:5672)\" }\n{ \"source\" : \"zookeeper\", \"message\": \"2000-09-07 14:07:41,508 [main] INFO  MyApp - Entering application.\" }\n{ \"source\" : \"zookeeper\", \"message\": \"54 [main] INFO MyApp.foo.bar - Entering application.\" }\n{ \"source\" : \"zookeeper\", \"message\": \"2000-09-07 14:07:44 INFO org.foo.bar:32 - Entering application.\" }\n{ \"source\" : \"elasticsearch\", \"message\": \"[2018-03-15T10:49:37,857][INFO ][index.search.slowlog.query] [i-0a78cf272c227585e] [8.1520909160000.4][0] took[6.9s], took_millis[6962], types[], stats[], search_type[QUERY_THEN_FETCH], total_shards[2], source[{\\\"size\\\":0,\\\"timeout\\\":\\\"1m\\\",\\\"query\\\":\\\"myquery}]\" }\n{ \"source\" : \"elasticsearch\", \"message\": \"[2018-03-15T11:18:32,097][TRACE][index.indexing.slowlog.index] [i-0fb0942bc5af92a50] [62.1520954640000.0\\/mzEo0np9TE67-TZfLSizUQ] took[211.4ms], took_millis[211], type[event], id[AWIpYf-elx3mYSdfhef5], routing[] , source[{\\\"tag\\\":{\\\"role\\\":\\\"alerting-metric-evaluator\\\",\\\"name\\\":\\\"alerting-metric-evaluator\\\",\\\"source\\\":\\\"\\\",\\\"env\\\":\\\"staging\\\",\\\"availability-zone\\\":\\\"us-east-1d\\\"},\\\"timestamp\\\":\\\"2018-03-15T11:18:31.066Z\\\",\\\"tiebreaker\\\":-724304927,\\\"service\\\":\\\"alerting-metric-query\\\",\\\"status\\\":\\\"info\\\",\\\"host\\\":\\\"i-0a88da725e2bf2373\\\",\\\"tags\\\":[\\\"worker_id:2\\\",\\\"service:alerting-metric-query\\\",\\\"source:\\\",\\\"lsb_codename:trusty\\\",\\\"lsb_id:ubuntu\\\",\\\"lsb_release:14.04\\\",\\\"account:staging\\\",\\\"autoscaling.managed:true\\\",\\\"autoscaling_group:alerting-metric-evaluator-anomaly\\\",\\\"availability-zone:us-east-1d\\\",\\\"aws_account:727006795293\\\",\\\"ec2_churn:666\\\",\\\"iam_profile:dd-common-profile\\\",\\\"image:ami-09192173\\\",\\\"instance-type:r4.2xlarge\\\",\\\"kernel:none\\\",\\\"name:alerting-metric-evaluator\\\",\\\"region:us-east-1\\\",\\\"security-group-name:alerting-metric-evaluator\\\",\\\"security-group-name:common\\\",\\\"security_group_name:alerting-metric-evaluator\\\",\\\"security_group_name:common\\\",\\\"team:bourbon\\\",\\\"team:yuzu\\\",\\\"terraform.managed:true\\\",\\\"terraform.module:alerting-metric-evaluator\\\",\\\"terraform.module:vpc-comm]\" }\n{ \"source\" : \"elasticsearch\", \"message\": \"[2018-03-15T10:49:37,857][INFO ][foo.bar] new node installed\" }\n{ \"source\" : \"elasticsearch\", \"message\": \"[2018-06-05 10:06:31,687][INFO ][cluster.metadata         ] [elasticsnoop_node_two] [test-index] creating index, cause [api], templates [], shards [5]\\/[1], mappings []\" }\n{ \"source\" : \"kafka\", \"message\": \"2000-09-07 14:07:41,508 [main] INFO  MyApp - Entering application.\" }\n{ \"source\" : \"kafka\", \"message\": \"54 [main] INFO MyApp.foo.bar - Entering application.\" }\n{ \"source\" : \"kafka\", \"message\": \"2000-09-07 14:07:44 INFO org.foo.bar:32 - Entering application.\" }\n{ \"source\" : \"kafka\", \"message\": \"[2020-03-12 16:23:32,543] INFO [ProducerStateManager partition=my_partition] Writing producer snapshot at offset 172041391 (kafka.log.ProducerStateManager)\" }\n{ \"source\" : \"couchdb\", \"message\": \"[Wed, 29 Aug 2018 11:53:11 GMT] [info] [\u003c0.404.0\u003e] 127.0.0.1 - - DELETE \\/new_database\\/random_task?rev=2-4cc3dfb6e76befd665faf124b36b7f1c 200\" }\n{ \"source\" : \"couchdb\", \"message\": \"2015-12-18 14:44:52.722 [info] Undefined \u003c0.7.0\u003e Application runtime_tools started on node 'node3@127.0.0.1'\" }\n{ \"source\" : \"couchdb\", \"message\": \"[error] 2018-08-29T00:00:14.470000Z couchdb@10.24.7.110 \u003c0.8925.6176\u003e -------- CRASH REPORT Process  (\u003c0.8925.6176\u003e) with 0 neighbors exited with reason: {normal,{gen_server,call,[\u003c0.16537.6180\u003e,close,infinity]}} at gen_server:terminate\\/7(line:826) \u003c= proc_lib:init_p_do_apply\\/3(line:240); initial_call: {couch_index_compactor,init,['Argument__1']}, ancestors: [\u003c0.19789.6149\u003e,\u003c0.6121.6149\u003e], messages: [], links: [], dictionary: [], trap_exit: true, status: running, heap_size: 376, stack_size: 27, reductions: 1888'\" }\n{ \"source\" : \"docker\", \"message\": \"172.17.0.1 - - [06\\/Jan\\/2017:16:16:37 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 404 612 \\\"http:\\/\\/www.perdu.com\\/\\\" \\\"Mozilla\\/5.0 (X11; Linux x86_64) AppleWebKit\\/537.36 (KHTML, like Gecko) Chrome\\/55.0.2883.87 Safari\\/537.36\\\" \\\"-\\\"\" }\n{ \"source\" : \"docker\", \"message\": \"2018-07-05 10:08:08 GMT | INFO | (runner.go:309 in work) | Done running check network\" }\n{ \"source\" : \"docker\", \"message\": \"W0601 14:20:25.000572       1 manager.go:147] Failed to get all responses in time (got 3\\/4)\" }\n{ \"source\" : \"docker\", \"message\": \"[ AGENT ] 2018-07-11 18:27:57 UTC | INFO | (transaction.go:121 in Process) | Successfully posted payload to \\\"https:\\/\\/6-3-0-app.agent.datadoghq.com\\/api\\/v1\\/series?api_key=*************************64a86\\\"\" }\n{ \"source\" : \"agent\", \"message\": \"2019-04-08 13:53:48 UTC | CORE | INFO | (pkg\\/collector\\/python\\/datadog_agent.go:120 in LogMessage) | kafka_cluster_status:8ca7b736f0aa43e5 | (kafka_cluster_status.py:213) | Checking for out of sync partition replicas\" }\n{ \"source\" : \"agent\", \"message\": \"2019-04-08 13:53:48 UTC | CORE | INFO | (pkg\\/collector\\/python\\/datadog_agent.go:121 in LogMessage) | - | (client.py:479) | Zookeeper connection established, state: CONNECTED\" }\n{ \"source\" : \"agent\", \"message\": \"2019-04-08 13:53:48 UTC | CORE | INFO | (pkg\\/collector\\/runner\\/runner.go:327 in work) | check:network,type:core | Done running check\" }\n{ \"source\" : \"agent\", \"message\": \"2019-04-08 13:53:48 UTC | CORE | INFO | (pkg\\/collector\\/runner\\/runner.go:264 in work) | Running check load\" }\n{ \"source\" : \"agent\", \"message\": \"2019-04-08 13:53:48 UTC | TRACE | INFO | (pkg\\/trace\\/agent\\/agent.go:145 in loop) | exiting\" }\n{ \"source\" : \"agent\", \"message\": \"2019-02-01 16:59:41 UTC | INFO | (connection_manager.go:124 in CloseConnection) | Connection closed\" }\n{ \"source\" : \"agent\", \"message\": \"2019-02-01 16:58:54 UTC | INFO | (serializer.go:263 in SendJSONToV1Intake) | Sent processes metadata payload, size: 1422 bytes.\" }\n{ \"source\" : \"agent\", \"message\": \"2020-01-03 15:37:00 UTC | SYS-PROBE | WARN | (pkg\\/ebpf\\/netlink\\/conntracker.go:301 in unregister) | exceeded maximum tracked short lived connections\" }\n{ \"source\" : \"agent\", \"message\": \"2020-11-18 10:31:13 UTC | JMX | INFO  | Instance | Done initializing JMX Server at localhost:7199\" }\n{ \"source\" : \"agent\", \"message\": \"2020-11-17 17:00:01 UTC | JMX | DEBUG | HttpClient | attempting to connect to: https:\\/\\/localhost:5001\\/agent\\/jmx\\/status\" }\n{ \"source\" : \"ruby\", \"message\": \"I, [1999-03-03T02:34:24.895701 #19074]  INFO -- Main: Some error.\" }\n{ \"source\" : \"ruby\", \"message\": \"method=GET path=\\/jobs\\/833552.json format=json controller=jobs action=show status=200 duration=58.33 view=40.43 db=15.26\" }\n{ \"source\" : \"ruby\", \"message\": \"I, [1999-03-03T02:34:24.895701 #19074]  INFO -- : Completed 200 OK in 41ms (Views: 0.2ms | ActiveRecord: 6.2ms)\" }\n{ \"source\" : \"ruby\", \"message\": \"I, [1999-03-03T02:34:24.895701 #19074]  INFO -- : Started GET \\\"\\/api\\/v1\\/example\\/query\\\" for 123.123.123.123 at 1999-03-03 02:34:24+0000\" }\n{ \"source\" : \"ruby\", \"message\": \"I, [1999-03-03T02:34:24.895701 #19074]  INFO -- : Processing by MyCheck::CheckController#index as JSON\" }\n{ \"source\" : \"ruby\", \"message\": \"I, [2018-06-27T08:01:52.991728 #1]  INFO -- : Received: {\\\"action\\\":\\\"cancel\\\",\\\"order\\\":{\\\"id\\\":1234567,\\\"timestamp\\\":153012312}}\" }\n{ \"source\" : \"ruby\", \"message\": \"[2019-01-16 15:38:45 +0000][my_app][WARN][dd.trace_id=7396234561907730428 dd.span_id=1152346429682372911] This is a test message!\" }\n{ \"source\" : \"ruby\", \"message\": \"[dd.trace_id=1321281354128614668 dd.span_id=5986620922286636160] Started GET \\\"\\/db\\\" for 172.22.0.1 at 2019-01-16 18:04:47 +0000\" }\n{ \"source\" : \"ruby\", \"message\": \"[dd.trace_id=1321281354128614668 dd.span_id=5986620922286636160] Processing by DatabaseController#index as *\\/*\" }\n{ \"source\" : \"ruby\", \"message\": \"[dd.trace_id=1321281354128614668 dd.span_id=5986620922286636160] Completed 200 OK in 9ms (Views: 6.3ms | ActiveRecord: 1.0ms)\" }\n{ \"source\" : \"ruby\", \"message\": \"I, [2019-09-24T17:24:34.414676 #1]  INFO -- : [dd.trace_id=1748205551911478249 dd.span_id=387648978129867948] Started GET \\\"\\/notes\\/1\\\" for 192.168.80.1 at 2019-09-24 17:24:34 +0000\" }\n{ \"source\" : \"ruby\", \"message\": \"I, [2019-09-24T17:24:34.414676 #1]  INFO -- : [dd.env=dev-env dd.service=sample-app dd.version=1.2.3-beta dd.trace_id=1748205551911478249 dd.span_id=387648978129867948] Started GET \\\"\\/notes\\/1\\\" for 192.168.80.1 at 2019-09-24 17:24:34 +0000\" }\n{ \"source\" : \"ruby\", \"message\": \"[dd.env=dev-env dd.service=sample-app dd.version=1.2.3-beta dd.trace_id=1321281354128614668 dd.span_id=5986620922286636160] Completed 200 OK in 9ms (Views: 6.3ms | ActiveRecord: 1.0ms)\" }\n{ \"source\" : \"ruby\", \"message\": \"[dd.env=dev-env dd.service=sample-app dd.version=1.2.3-beta dd.trace_id=1321281354128614668 dd.span_id=5986620922286636160] Processing by DatabaseController#index as *\\/*\" }\n{ \"source\" : \"vault\", \"message\": \"2019-12-18T20:26:12.000Z [INFO]  core: security barrier not initialized\" }\n{ \"source\" : \"vault\", \"message\": \"2019-12-06T23:59:40.398Z [DEBUG] expiration: collecting leases\" }\n{ \"source\" : \"vault\", \"message\": \"2019-12-06T23:59:40.425Z [WARN]  no `api_addr` value specified in config or in VAULT_API_ADDR; falling back to detection if possible, but this value should be manually set\" }\n{ \"source\" : \"vault\", \"message\": \"{ \\\"time\\\": \\\"2019-11-05T00:40:27.638711Z\\\", \\\"type\\\": \\\"request\\\", \\\"auth\\\": { \\\"client_token\\\": \\\"hmac-sha256:6291b17ab99eb5bf3fd44a41d3a0bf0213976f26c72d12676b33408459a89885\\\", \\\"accessor\\\": \\\"hmac-sha256:2630a7b8e996b0c451db4924f32cec8793d0eb69609f777d89a5c8188a742f52\\\", \\\"display_name\\\": \\\"root\\\", \\\"policies\\\": [ \\\"root\\\" ], \\\"token_policies\\\": [ \\\"root\\\" ], \\\"token_type\\\": \\\"service\\\" }, \\\"request\\\": { \\\"id\\\": \\\"9adb5544-637f-3d42-9459-3684f5d21996\\\", \\\"operation\\\": \\\"update\\\", \\\"client_token\\\": \\\"hmac-sha256:6291b17ab99eb5bf3fd44a41d3a0bf0213976f26c72d12676b33408459a89885\\\", \\\"client_token_accessor\\\": \\\"hmac-sha256:2630a7b8e996b0c451db4924f32cec8793d0eb69609f777d89a5c8188a742f52\\\", \\\"namespace\\\": { \\\"id\\\": \\\"root\\\" }, \\\"path\\\": \\\"sys\\/policies\\/acl\\/admin\\\", \\\"data\\\": { \\\"policy\\\": \\\"hmac-sha256:212744709e5a643a5ff4125160c26983f8dab537f60d166c2fac5b95547abc33\\\" }, \\\"remote_address\\\": \\\"127.0.0.1\\\" } }\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"172.17.0.1 - [172.17.0.1] - - [07\\/Dec\\/2018:18:31:33 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 200 261 \\\"-\\\" \\\"Mozilla\\/5.0 (Windows NT 5.1; rv:31.0) Gecko\\/20100101 Firefox\\/31.0\\\" 1904 0.011 [proxyname-8080] 172.17.0.1:9000 298 0.012 200 abcdefg12345abcdef\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"172.17.0.1 - - [07\\/Dec\\/2018:18:31:33 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 200 261 \\\"-\\\" \\\"Mozilla\\/5.0 (Windows NT 5.1; rv:31.0) Gecko\\/20100101 Firefox\\/31.0\\\" 1904 0.011 [proxyname-8080] 172.17.0.1:9000 298 0.012 200 abcdefg12345abcdef\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"2017\\/09\\/26 14:36:50 [error] 8409#8409: *317058 \\\"\\/usr\\/share\\/nginx\\/html\\/sql\\/sql-admin\\/index.html\\\" is not found (2: No such file or directory), client: 217.92.148.44, server: localhost, request: \\\"HEAD http:\\/\\/174.138.82.103:80\\/sql\\/sql-admin\\/ HTTP\\/1.1\\\", host: \\\"174.138.82.103\\\"\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"2017\\/09\\/26 14:36:50 [info] 14#14: *285 client 172.17.0.27 closed keepalive connection\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"I1221 13:00:58.488494       7 controller.go:202] Initial sync, sleeping for 1 second.\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"172.17.0.1 - [172.17.0.1] - - [07\\/Dec\\/2018:18:31:33 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 200 261 \\\"-\\\" \\\"Mozilla\\/5.0 (Windows NT 5.1; rv:31.0) Gecko\\/20100101 Firefox\\/31.0\\\" 1904 0.011 [proxyname-8080] 172.17.0.1:9000 298 0.012 200\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"172.17.0.1 - [172.17.0.1] - - [07\\/Dec\\/2018:18:31:33 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 200 261 \\\"-\\\" \\\"Mozilla\\/5.0 (Windows NT 5.1; rv:31.0) Gecko\\/20100101 Firefox\\/31.0\\\" 1904 0.011 [proxyname-8080] 172.17.0.1:9000, 100.110.0.3:80 298, 0 0.012, - 200, - abcdefg12345abcdef\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"172.17.0.1 - [172.17.0.1] - - [07\\/Dec\\/2018:18:31:33 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 200 261 \\\"-\\\" \\\"Mozilla\\/5.0 (Windows NT 5.1; rv:31.0) Gecko\\/20100101 Firefox\\/31.0\\\" 1904 0.011 [proxyname-8080] 172.17.0.1:9000, 100.110.0.3:80 298, 0 0.012, 0.013 200, - abcdefg12345abcdef\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"172.17.0.1 - [172.17.0.1] - - [07\\/Dec\\/2018:18:31:33 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 200 261 \\\"-\\\" \\\"Mozilla\\/5.0 (Windows NT 5.1; rv:31.0) Gecko\\/20100101 Firefox\\/31.0\\\" 1904 0.011 [proxyname-8080] 172.17.0.1:9000, 100.110.0.3:80, 100.110.0.3:80 298, -, - 0.012, -, - 200, -, - abcdefg12345abcdef\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"172.17.0.1 - [172.17.0.1] - - [07\\/Dec\\/2018:18:31:33 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 200 261 \\\"-\\\" \\\"Mozilla\\/5.0 (Windows NT 5.1; rv:31.0) Gecko\\/20100101 Firefox\\/31.0\\\" 1904 0.011 [proxyname-8080] [alt-proxyname-8080] 172.17.0.1:9000 298 0.012 200 abcdefg12345abcdef\" }\n{ \"source\" : \"nginx-ingress-controller\", \"message\": \"172.16.99.64 - - [19\\/Mar\\/2020:16:02:20 +0000] \\\"GET \\/datadoghq\\/company?test=var1%20Pl HTTP\\/1.1\\\" 503 605 \\\"-\\\" \\\"Mozilla\\/5.0 (Windows NT 5.1; rv:31.0) Gecko\\/20100101 Firefox\\/31.0\\\" 4033 0.000 [proxyname-8080] [] - - - - abcdefg12345abcdef\" }\n{ \"source\" : \"mysql\", \"message\": \"2017-12-29T12:33:33.095243Z         2 Query     SELECT TABLE_SCHEMA, TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE CREATE_OPTIONS LIKE partiion;\" }\n{ \"source\" : \"mysql\", \"message\": \"2017-12-29T12:04:09.954078Z 0 [Warning] System table \\\"plugin\\\" is expected to be transactional.\" }\n{ \"source\" : \"mysql\", \"message\": \"171113 14:14:20  InnoDB: Shutdown completed; log sequence number 1595675\" }\n{ \"source\" : \"mysql\", \"message\": \"201210 20:58:16\\t424242 Query\\tSELECT option_value FROM galaxy_guide WHERE option_name = 'zaphod' LIMIT 1;\\n\" }\n{ \"source\" : \"mysql\", \"message\": \"424242 Query\\tSELECT option_value FROM galaxy_guide WHERE option_name = 'trillian' LIMIT 1;\\n\" }\n{ \"source\" : \"mysql\", \"message\": \"2021-07-06  7:29:32 0 [Warning] You need to use --log-bin to make --expire-logs-days or --binlog-expire-logs-seconds work.\\n\" }\n{ \"source\" : \"mysql\", \"message\": \"2016-06-15 16:53:33 139651251140544 [Note] InnoDB: The InnoDB memory heap is disabled\\n\" }\n{ \"source\" : \"mysql\", \"message\": \"2016-06-15  7:53:33 139651251140544 [Note] InnoDB: The InnoDB memory heap is disabled\\n\" }\n{ \"source\" : \"mysql\", \"message\": \"# Query_time: 0.214922  Lock_time: 0.000184 Rows_sent: 248832  Rows_examined: 72\\nSET timestamp=1574851393;\\nSELECT * FROM fruit f1, fruit f2, fruit f3, fruit f4, fruit f5;\\n\" }\n{ \"source\" : \"mysql\", \"message\": \"# Time: 2019-11-27T10:43:13.460744Z\\n# User@Host: root[root] @ localhost [1.2.3.4]  Id:    35\\n# Query_time: 0.214922  Lock_time: 0.000184 Rows_sent: 248832  Rows_examined: 72\\nSET timestamp=1574851393;\\nSELECT * FROM fruit f1, fruit f2, fruit f3, fruit f4, fruit f5;\\n\" }\n{ \"source\" : \"mysql\", \"message\": \"# Time: 2019-11-27T10:43:13.460744Z\\n# User@Host: root[root] @ localhost []  Id:    35\\n# Query_time: 0.214922  Lock_time: 0.000184 Rows_sent: 248832  Rows_examined: 72\\n# Thread_id: 55   Killed: 0  Errno: 0\\n# Bytes_sent: 123456   Bytes_received: 0\\nSET timestamp=1574851393;\\nSELECT * FROM fruit f1, fruit f2, fruit f3, fruit f4, fruit f5\\n\" }\n{ \"source\" : \"mysql\", \"message\": \"# Time: 191127 15:45:44\\n# User@Host: root[root] @ localhost [1.2.3.4]\\n# Thread_id: 55  Schema: app  QC_hit: No\\n# Query_time: 0.214922  Lock_time: 0.000159 Rows_sent: 248832  Rows_examined: 12\\n# Rows_affected: 0\\nuse app;\\nSET timestamp=1574869544;\\nSELECT * FROM fruit f1, fruit f2, fruit f3, fruit f4, fruit f5;\\n\" }\n{ \"source\" : \"mysql\", \"message\": \"# Time: 191127 15:45:44\\n# User@Host: root[root] @ localhost [1.2.3.4]\\n# Thread_id: 55  Schema: app  Last_errno: 0  Killed: 0\\n# Query_time: 0.214922  Lock_time: 0.000159 Rows_sent: 248832  Rows_examined: 12  Rows_affected: 0\\n# Bytes_sent: 123456\\n# Stored_routine: fruit.five_product\\nuse app;\\nSET timestamp=1574869544;\\nSELECT * FROM fruit f1, fruit f2, fruit f3, fruit f4, fruit f5;\\n\" }\n{ \"source\" : \"cluster-autoscaler\", \"message\": \"I0402 08:06:51.571361       1 static_autoscaler.go:366] Calculating unneeded nodes\" }\n{ \"source\" : \"cluster-autoscaler\", \"message\": \"I0402 08:06:51.571361       1 scale_down.go:414] Node ip-10-61-112-221.eu-west-2.compute.internal is not suitable for removal - utilization too big (0.908163)\" }\n{ \"source\" : \"cluster-autoscaler\", \"message\": \"E0402 08:06:51.571361       1 utils.go:60] pod.Status.StartTime is nil for pod friz-ws-8929cabd74a-stfz4. Should not reach here.\" }\n{ \"source\" : \"aws-alb-ingress-controller\", \"message\": \"I0408 21:09:06.840010       1 store.go:226] updating annotations information for ingress ref-prod\\/dre-proxy\" }\n{ \"source\" : \"aws-alb-ingress-controller\", \"message\": \"I0408 21:09:06.840010       1 rules.go:98] ref-prod\\/ref-prod-ingress: rule 2 modified with conditions [{    Field: \\\"host-header\\\",    Values: [\\\"oauth2-int.us-east-1.ref-prod.wds.io\\\"]  },{    Field: \\\"path-pattern\\\",    Values: [\\\"\\/*\\\"]  }]\" }\n{ \"source\" : \"aws-alb-ingress-controller\", \"message\": \"W0408 21:09:06.840010       1 reflector.go:270] pkg\\/mod\\/k8s.io\\/client-go@v2.0.0-alpha.0.0.20191112141123-5c4ab214ef58+incompatible\\/utils\\/cache\\/reflector.go:95: watch of *v1.Endpoints ended with: too old resource version: 98851296 (98851900)\" }\n{ \"source\" : \"proxysql\", \"message\": \"2020-04-06 08:59:07 MySQL_Monitor.cpp:960:monitor_read_only_thread(): [ERROR] Timeout on read_only check for db:3306 after 2ms. Unable to create a connection. If the server is overload, increase mysql-monitor_connect_timeout. Error: timeout on creating new connection: Can't connect to MySQL server on 'db' (115).\" }\n{ \"source\" : \"proxysql\", \"message\": \"2020-04-06 08:59:08 [INFO] New mysql_aws_aurora_hostgroups table\" }\n{ \"source\" : \"proxysql\", \"message\": \"Standard MySQL Authentication rev. 0.2.0902 -- MySQL_Authentication.cpp -- Tue Oct 15 17:03:55 2019\" }\n{ \"source\" : \"proxysql\", \"message\": \"{\\\"client_addr\\\":\\\"127.0.0.1:39954\\\",\\\"event\\\":\\\"Admin_Connect_ERR\\\",\\\"schemaname\\\":\\\"test\\\",\\\"ssl\\\":false,\\\"thread_id\\\":2,\\\"proxy_addr\\\":\\\"0.0.0.0:6033\\\",\\\"time\\\":\\\"2019-05-20 18:48:47.631\\\",\\\"timestamp\\\":1558342127631,\\\"username\\\":\\\"admin\\\"}\" }\n{ \"source\" : \"proxysql\", \"message\": \"{\\\"client_addr\\\":\\\"127.0.0.1:39954\\\",\\\"creation_time\\\":\\\"2019-05-20 18:48:47.631\\\",\\\"duration\\\":\\\"125.02ms\\\",\\\"event\\\":\\\"Admin_Close\\\",\\\"extra_info\\\":\\\"MySQL_Thread.cpp:2652:~MySQL_Thread()\\\",\\\"schemaname\\\":\\\"test\\\",\\\"ssl\\\":false,\\\"thread_id\\\":2,\\\"time\\\":\\\"2019-05-20 18:48:47.631\\\",\\\"timestamp\\\":1558342127631,\\\"username\\\":\\\"admin\\\"}\" }\n{ \"source\" : \"proxysql\", \"message\": \"{\\\"client\\\":\\\"127.0.0.1:39958\\\",\\\"digest\\\":\\\"0x98A2503010E9E4C8\\\",\\\"duration_us\\\":366,\\\"endtime\\\":\\\"2019-07-14 18:06:03.285029\\\",\\\"endtime_timestamp_us\\\":1563091563285029,\\\"event\\\":\\\"COM_STMT_PREPARE\\\",\\\"hostgroup_id\\\":0,\\\"query\\\":\\\"SELECT id,id2 FROM test1 WHERE id \u003c ?\\\",\\\"rows_affected\\\":0,\\\"rows_sent\\\":0,\\\"schemaname\\\":\\\"test\\\",\\\"server\\\":\\\"127.0.0.1:3306\\\",\\\"starttime\\\":\\\"2019-07-14 18:06:03.284663\\\",\\\"starttime_timestamp_us\\\":1563091563284663,\\\"thread_id\\\":3,\\\"username\\\":\\\"sbtest\\\"}\" }\n{ \"source\" : \"azure\", \"message\": \"{\\\"resourceId\\\": \\\"\\/SUBSCRIPTIONS\\/8C56D827-5F07-45CE-8F2B-6C5001DB5C6F\\/RESOURCEGROUPS\\/KITCHEN-DD-AGENT-WIN2019-AZURE-20200407T115109PL2363814-A6\\/PROVIDERS\\/MICROSOFT.COMPUTE\\/VIRTUALMACHINES\\/DDATWIN2019\\\",\\\"category\\\": \\\"Administrative\\\",\\\"callerIpAddress\\\": \\\"34.224.243.198\\\",\\\"level\\\": \\\"Warning\\\",\\\"operationName\\\": \\\"MICROSOFT.AUTHORIZATION\\/POLICIES\\/AUDIT\\/ACTION\\\",\\\"correlationId\\\": \\\"aea8188d-9be4-48c7-9e8f-3bf10a545ff3\\\",\\\"time\\\": \\\"2020-04-07T12:01:17.8810661Z\\\",\\\"resultType\\\": \\\"Success\\\",\\\"durationMs\\\": 123,\\\"resultSignature\\\": \\\"Succeeded.\\\", \\\"identity\\\": {\\\"authorization\\\": {\\\"evidence\\\": {\\\"principalId\\\": \\\"5f6793e4783e49a2bfb8cdaasdada\\\"}}}}\" }\n{ \"source\" : \"azure.web\", \"message\": \"{\\\"resourceId\\\": \\\"\\/SUBSCRIPTIONS\\/8C56D827-5F07-45CE-8F2B-6C5001DB5C6F\\/RESOURCEGROUPS\\/KITCHEN-DD-AGENT-WIN2019-AZURE-20200407T115109PL2363814-A6\\/PROVIDERS\\/MICROSOFT.COMPUTE\\/VIRTUALMACHINES\\/DDATWIN2019\\\",\\\"category\\\": \\\"Administrative\\\",\\\"callerIpAddress\\\": \\\"34.224.243.198\\\",\\\"level\\\": \\\"Warning\\\",\\\"operationName\\\": \\\"MICROSOFT.WEB\\/SITES\\/EXTENSIONS\\/WRITE\\\",\\\"correlationId\\\": \\\"aea8188d-9be4-48c7-9e8f-3bf10a545ff3\\\",\\\"time\\\": \\\"2020-04-07T12:01:17.8810661Z\\\",\\\"resultType\\\": \\\"Success\\\",\\\"durationMs\\\": 123,\\\"resultSignature\\\": \\\"Succeeded.\\\", \\\"identity\\\": {\\\"authorization\\\": {\\\"evidence\\\": {\\\"principalId\\\": \\\"5f6793e4783e49a2bfb8cdaasdada\\\"}}}}\" }\n{ \"source\" : \"azure.storage\", \"message\": \"{\\\"resourceId\\\": \\\"\\/SUBSCRIPTIONS\\/8C56D827-5F07-45CE-8F2B-6C5001DB5C6F\\/RESOURCEGROUPS\\/CONTAINERGROUP\\/PROVIDERS\\/MICROSOFT.STORAGE\\/STORAGEACCOUNTS\\/B7UI4VJGWZ6EODIAG0\\\",\\\"category\\\": \\\"Administrative\\\",\\\"callerIpAddress\\\": \\\"104.209.130.4\\\",\\\"level\\\": \\\"Error\\\",\\\"operationName\\\": \\\"MICROSOFT.STORAGE\\/STORAGEACCOUNTS\\/LISTKEYS\\/ACTION\\\",\\\"correlationId\\\": \\\"f860428d-66c1-4639-a3da-b963663f892f\\\",\\\"time\\\": \\\"2020-04-04T02:48:41.1195332Z\\\",\\\"resultType\\\": \\\"Failure\\\",\\\"durationMs\\\": 28455,\\\"resultSignature\\\": \\\"Failed.InternalServerError\\\", \\\"identity\\\": {\\\"authorization\\\": {\\\"evidence\\\": {\\\"principalId\\\": \\\"5f6793e4783e49a2bfb8cdaasdada\\\"}}}}\" }\n{ \"source\" : \"azure.network\", \"message\": \"{\\\"resourceId\\\": \\\"\\/SUBSCRIPTIONS\\/8C56D827-5F07-45CE-8F2B-6C5001DB5C6F\\/RESOURCEGROUPS\\/KITCHEN-DD-AGENT-WIN2019-AZURE-20200407T115109PL2363814-A6\\/PROVIDERS\\/MICROSOFT.COMPUTE\\/VIRTUALMACHINES\\/DDATWIN2019\\\",\\\"category\\\": \\\"Administrative\\\",\\\"callerIpAddress\\\": \\\"34.224.243.198\\\",\\\"level\\\": \\\"Warning\\\",\\\"operationName\\\": \\\"MICROSOFT.AUTHORIZATION\\/POLICIES\\/AUDIT\\/ACTION\\\",\\\"correlationId\\\": \\\"aea8188d-9be4-48c7-9e8f-3bf10a545ff3\\\",\\\"time\\\": \\\"2020-04-07T12:01:17.8810661Z\\\",\\\"resultType\\\": \\\"Success\\\",\\\"durationMs\\\": 123,\\\"resultSignature\\\": \\\"Succeeded.\\\", \\\"identity\\\": {\\\"authorization\\\": {\\\"evidence\\\": {\\\"principalId\\\": \\\"5f6793e4783e49a2bfb8cdaasdada\\\"}}}}\" }\n{ \"source\" : \"azure.network\", \"message\": \"{\\\"resourceId\\\": \\\"\\/SUBSCRIPTIONS\\/8C56D827-5F07-45CE-8F2B-6C5001DB5C6F\\/RESOURCEGROUPS\\/HETANSH-RESOURCE-GROUP-FOR-TESTING\\/PROVIDERS\\/MICROSOFT.NETWORK\\/FRONTDOORS\\/HETANSHTEST\\\",\\\"category\\\": \\\"ResourceHealth\\\",\\\"properties\\\": {\\\"eventCategory\\\": \\\"ResourceHealth\\\",\\\"eventProperties\\\": {\\\"cause\\\": \\\"PlatformInitiated\\\",\\\"details\\\": \\\"\\\",\\\"currentHealthStatus\\\": \\\"Unavailable\\\",\\\"previousHealthStatus\\\": \\\"Available\\\",\\\"title\\\": \\\"Front Door service has detected global availability drops impacting one or more regions. The issue may cause failures for client requests sent to this Front Door resource.\\\",\\\"type\\\": \\\"Downtime\\\"}},\\\"level\\\": \\\"Critical\\\",\\\"correlationId\\\": \\\"699a9793-d7d7-4613-b58a-0018da23b2cb\\\",\\\"operationName\\\": \\\"Microsoft.Resourcehealth\\/healthevent\\/Activated\\/action\\\",\\\"time\\\": \\\"2020-04-06T10:54:44.4707124Z\\\",\\\"resultType\\\": \\\"Active\\\", \\\"identity\\\": {\\\"authorization\\\": {\\\"evidence\\\": {\\\"principalId\\\": \\\"5f6793e4783e49a2bfb8cdaasdada\\\"}}}}\" }\n{ \"source\" : \"azure.compute\", \"message\": \"{\\\"resourceId\\\": \\\"\\/SUBSCRIPTIONS\\/8C56D827-5F07-45CE-8F2B-6C5001DB5C6F\\/RESOURCEGROUPS\\/KITCHEN-DD-AGENT-WIN2019-AZURE-20200407T115109PL2363814-A6\\/PROVIDERS\\/MICROSOFT.COMPUTE\\/VIRTUALMACHINES\\/DDATWIN2019\\\",\\\"category\\\": \\\"Administrative\\\",\\\"callerIpAddress\\\": \\\"34.224.243.198\\\",\\\"level\\\": \\\"Warning\\\",\\\"operationName\\\": \\\"MICROSOFT.AUTHORIZATION\\/POLICIES\\/AUDIT\\/ACTION\\\",\\\"correlationId\\\": \\\"aea8188d-9be4-48c7-9e8f-3bf10a545ff3\\\",\\\"time\\\": \\\"2020-04-07T12:01:17.8810661Z\\\",\\\"resultType\\\": \\\"Success\\\",\\\"durationMs\\\": 123,\\\"resultSignature\\\": \\\"Succeeded.\\\", \\\"identity\\\": {\\\"authorization\\\": {\\\"evidence\\\": {\\\"principalId\\\": \\\"5f6793e4783e49a2bfb8cdaasdada\\\"}}}}\" }\n{ \"source\" : \"azure.compute\", \"message\": \"{\\\"resourceId\\\": \\\"\\/SUBSCRIPTIONS\\/8C56D827-5F07-45CE-8F2B-6C5001DB5C6F\\/RESOURCEGROUPS\\/KITCHEN-DD-AGENT-SLES-12-AZURE-20200408T112721PL2367806-A6\\/PROVIDERS\\/MICROSOFT.COMPUTE\\/VIRTUALMACHINES\\/DD-AGENT-TESTING-SLES-12-AZURE\\\",\\\"category\\\": \\\"ResourceHealth\\\",\\\"properties\\\": {\\\"eventCategory\\\": \\\"ResourceHealth\\\",\\\"eventProperties\\\": {\\\"cause\\\": \\\"PlatformInitiated\\\",\\\"details\\\": \\\"Unknown\\\",\\\"currentHealthStatus\\\": \\\"Unavailable\\\",\\\"previousHealthStatus\\\": \\\"Unavailable\\\",\\\"title\\\": \\\"Down: Virtual machine has been unavailable for 15 minutes\\\",\\\"type\\\": \\\"Downtime\\\"}},\\\"level\\\": \\\"Critical\\\",\\\"correlationId\\\": \\\"dba965ff-6161-4837-a2bf-95b355ddf2d0\\\",\\\"operationName\\\": \\\"Microsoft.Resourcehealth\\/healthevent\\/Updated\\/action\\\",\\\"time\\\": \\\"2020-04-08T11:49:12.1063734Z\\\",\\\"resultType\\\": \\\"Updated\\\", \\\"identity\\\": {\\\"authorization\\\": {\\\"evidence\\\": {\\\"principalId\\\": \\\"5f6793e4783e49a2bfb8cdaasdada\\\"}}}}\" }\n{ \"source\" : \"etcd\", \"message\": \"2020-08-20 18:19:25.769683 I | embed: ready to serve client requests\" }\n{ \"source\" : \"etcd\", \"message\": \"2020-08-20 18:23:44.714594 W | rafthttp: lost the TCP streaming connection with peer d282ac2ce600c1ce (stream Message reader)\" }\n{ \"source\" : \"glog\", \"message\": \"I0402 08:06:51.571361       1 static_autoscaler.go:366] Calculating unneeded nodes\" }\n{ \"source\" : \"glog\", \"message\": \"I0402 08:06:51.571361       1 k8sclient.go:251] Replicas are not as expected : updating replicas from 37 to 36\" }\n{ \"source\" : \"glog\", \"message\": \"E0402 08:06:51.571361       1 authentication.go:65] Unable to authenticate the request due to an error: x509: certificate has expired or is not yet valid\" }\n{ \"source\" : \"auth0\", \"message\": \"{\\\"log_id\\\":\\\"90020200123T15145913700000000000000000000000000000000000\\\",\\\"data\\\":{\\\"date\\\":\\\"2020-01-23T15:14:59.137Z\\\",\\\"tenant\\\":\\\"datadog\\\",\\\"log_id\\\":\\\"90020200123T15145913700000000000000000000000000000000000\\\",\\\"type\\\":\\\"feoobft\\\",\\\"connection\\\":\\\"great-pollo\\\",\\\"connection_id\\\":\\\"con_DFOp2K6Ysya1y2OP\\\",\\\"client_id\\\":\\\"61PIEqk9Hd4hXJFZhoBZ5bNmN349coz1\\\",\\\"client_name\\\":\\\"greatballena\\\",\\\"ip\\\":\\\"79.153.77.39\\\",\\\"user_agent\\\":\\\"Mozilla\\/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\\/537.36 (KHTML, like Gecko) Chrome\\/71.0.3578.98 Safari\\/537.36\\\",\\\"details\\\":\\\"whatever...\\\",\\\"hostname\\\":\\\"awesome.bisonte.auth0.com\\\",\\\"user_id\\\":\\\"auth0|61PIEqk9Hd4hXJFZhoBZ5bNmN349coz1\\\",\\\"user_name\\\":\\\"cleveráguila\\\",\\\"strategy\\\":\\\"auth0\\\",\\\"strategy_type\\\":\\\"database\\\",\\\"description\\\":\\\"waaaaa\\\"}}\" }\n{ \"source\" : \"auth0\", \"message\": \"{\\\"log_id\\\":\\\"90020200123T15145913700000000000000000000000000000000000\\\",\\\"data\\\":{\\\"date\\\":\\\"2020-01-23T15:14:59.137Z\\\", \\\"type\\\":\\\"admin_update_launch\\\", \\\"description\\\":\\\"Auth0 has launched a new admin update\\\"}}\" }\n{ \"source\" : \"kube_scheduler\", \"message\": \"W0424 11:47:41.605188       1 authorization.go:47] Authorization is disabled\" }\n{ \"source\" : \"kube_scheduler\", \"message\": \"I0424 11:47:41.605254       1 deprecated_insecure_serving.go:49] Serving healthz insecurely on 127.0.0.1:10251\" }\n{ \"source\" : \"kube_scheduler\", \"message\": \"E0424 11:47:46.923664       1 reflector.go:134] k8s.io\\/client-go\\/informers\\/factory.go:132: Failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User \\\"system:kube-scheduler\\\" cannot list resource \\\"persistentvolumeclaims\\\" in API group \\\"\\\" at the cluster scope\" }\n{ \"source\" : \"amazon-ecs-agent\", \"message\": \"2019-08-01T15:45:13Z [INFO] Managed task [arn:aws:ecs:us-east-1:123456789012:task\\/12345c0c-123b-1234-bea2-fc1123d1234a]: waiting for event for task\" }\n{ \"source\" : \"amazon-ecs-agent\", \"message\": \"2019-08-01T15:28:07Z [INFO] Managed task [arn:aws:ecs:us-east-1:123456789012:task\\/test-dev-test-ecs-general\\/123456e12a2c1234bf311e12a1d123a1]: got resource [cgroup] event: [CREATED]\" }\n{ \"source\" : \"amazon-ecs-agent\", \"message\": \"2019-08-01T15:18:23Z 200 123.11.0.1:12345 \\\"\\/v2\\/credentials\\\" \\\"Java\\/1.8.0_111\\\" arn:aws:ecs:eu-west-1:123456789012:task\\/12f3b123-d12e-4c12-9ed0-a89daaf12345 GetCredentials 2 test-dev-test-ecs-general arn:aws:ecs:eu-west-1:123456789012:container-instance\\/test-dev-test-ecs-general\\/2bcef0cd123456a234f7cffb234bb234\" }\n{ \"source\" : \"amazon-ecs-agent\", \"message\": \"2019-08-01T14:59:17Z [INFO] Managed task [arn:aws:ecs:us-east-1:123456789012:task\\/123ea123-1234-4c4e-a123-8cf4daw4d6sa]: task not steady state or terminal; progressing it\" }\n{ \"source\" : \"amazon-ecs-agent\", \"message\": \"2019-08-01T14:47:05Z [INFO] Saving state! module=\\u201Cstatemanager\\\"\" }\n{ \"source\" : \"amazon-ecs-agent\", \"message\": \"2019-08-01T14:54:04Z [INFO] Managed task [arn:aws:ecs:us-west-2:123456789012:task\\/test-dev-test-ecs-general\\/c23f3b3f9be12345a123f8a8bf0e1234]: no longer waiting\" }\n{ \"source\" : \"amazon-ecs-agent\", \"message\": \"level=info time=2019-12-12T23:43:29Z msg=\\\"Loading configuration\\\" module=agent.go\" }\n{ \"source\" : \"nodejs\", \"message\": \"{\\\"name\\\":\\\"myapp\\\",\\\"hostname\\\":\\\"COMP11257.local\\\",\\\"pid\\\":10428,\\\"level\\\":10,\\\"msg\\\":\\\"trace log\\\",\\\"time\\\":\\\"2019-10-21T19:13:23.185Z\\\",\\\"v\\\":0}\" }\n{ \"source\" : \"nodejs\", \"message\": \"{\\\"level\\\":50,\\\"time\\\":1571685203246,\\\"pid\\\":10429,\\\"hostname\\\":\\\"COMP11257.local\\\",\\\"msg\\\":\\\"error log\\\",\\\"v\\\":1}\" }\n{ \"source\" : \"nodejs\", \"message\": \"[2019-10-21T15:13:23.419] [INFO] default - An info message\" }\n{ \"source\" : \"nodejs\", \"message\": \"[dd.trace_id=123abc dd.span_id=1234abc] [2019-10-21T15:13:23.419] [INFO] default - An info message\" }\n{ \"source\" : \"nodejs\", \"message\": \"[2019-10-21T15:13:23.419] [INFO] default - [dd.trace_id=123abc dd.span_id=1234abc] An info message\" }\n{ \"source\" : \"nodejs\", \"message\": \"GET www.google.com 304 5000 - 2.306 ms\" }\n{ \"source\" : \"nodejs\", \"message\": \"::1 - - [21\\/Oct\\/2019:19:16:34 +0000] \\\"GET \\/ HTTP\\/1.1\\\" 504 - \\\"-\\\" \\\"Mozilla\\/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit\\/537.36 (KHTML, like Gecko) Chrome\\/77.0.3865.90 Safari\\/537.36\\\"\" }\n{ \"source\" : \"nodejs\", \"message\": \"[dd.trace_id=123abc dd.span_id=1234abc] { \\\"level\\\": \\\"info\\\", \\\"message\\\": \\\"This is a json message\\\" }\" }\n{ \"source\" : \"nodejs\", \"message\": \"[dd.service=excelsior dd.env=jesse-dev dd.version=abc123 dd.trace_id=123abc dd.span_id=1234abc] { \\\"level\\\": \\\"info\\\", \\\"message\\\": \\\"This is a json message\\\" }\" }\n{ \"source\" : \"nodejs\", \"message\": \"[dd.service=excelsior dd.env=jesse-dev dd.version=abc123 dd.trace_id=123abc dd.span_id=1234abc] [2019-10-21T15:13:23.419] [INFO] default - An info message\" }\n{ \"source\" : \"nodejs\", \"message\": \"[2019-10-21T15:13:23.419] [INFO] default - [dd.service=excelsior dd.env=jesse-dev dd.version=abc123 dd.trace_id=123abc dd.span_id=1234abc] An info message\" }\n{ \"source\" : \"postgresql\", \"message\": \"2017-11-07 17:30:39 UTC LOG:  incomplete startup packet\" }\n{ \"source\" : \"postgresql\", \"message\": \"2017-11-08 18:11:35.727 UTC [5237] postgres psql postgres [local] 5a0348cd.1475 LOG:  statement: SELECT * FROM playground;\" }\n{ \"source\" : \"postgresql\", \"message\": \"2019-12-10 18:27:45.389 UTC [114] datadog_test datadog-agent datadog 172.28.0.1 5defc7c5.72 LOG:  duration: 0.140 ms  statement: select checkpoints_timed, checkpoints_req, buffers_checkpoint, buffers_clean, maxwritten_clean, buffers_backend, buffers_alloc, buffers_backend_fsync, checkpoint_write_time, checkpoint_sync_time FROM pg_stat_bgwriter\" }\n{ \"source\" : \"cassandra\", \"message\": \"WARN  [MemtableFlushWriter:20342] 2016-06-29 08:35:35,936  SSTableWriter.java:240 - Compacting large partition limo\\/read_audit_history:2016-6-29 (115624250 bytes)\" }\n{ \"source\" : \"cassandra\", \"message\": \"INFO  [SlabPoolCleaner] 2016-06-28 16:13:14,966  ColumnFamilyStore.java:1211 - Flushing largest CFS(Keyspace='order_store', ColumnFamily='orderdata') to free up room. Used total: 0.11\\/0.00, live: 0.11\\/0.00, flushing: 0.00\\/0.00, this: 0.10\\/0.10\" }\n{ \"source\" : \"cassandra\", \"message\": \"INFO  [SlabPoolCleaner] 2016-06-28 16:13:14,967  ColumnFamilyStore.java:905 - Enqueuing flush of orderdata: 216588472 (10%) on-heap, 0 (0%) off-heap\" }\n{ \"source\" : \"cassandra\", \"message\": \"INFO  [MemtableFlushWriter:320] 2016-06-28 16:13:14,969  Memtable.java:347 - Writing Memtable-orderdata@849528272(129.804MiB serialized bytes, 297813 ops, 10%\\/0% of on\\/off-heap limit)\" }\n{ \"source\" : \"cassandra\", \"message\": \"INFO  [MemtableFlushWriter:1] 2016-06-28 16:19:48,627  Memtable.java:382 - Completed flushing \\/app\\/cassandra\\/datastax\\/dse-data01\\/system\\/local-7ad54392bcdd35a684174e047860b377\\/system-local-tmp-ka-3981-Data.db (0.000KiB) for commitlog position ReplayPosition(segmentId=1467130786324, position=567)\" }\n{ \"source\" : \"cassandra\", \"message\": \"INFO  [CompactionExecutor:26] 2016-06-28 14:38:40,545  CompactionTask.java:274 - Compacted 2 sstables to [\\/app\\/cassandra\\/datastax\\/dse-data03\\/order_store\\/orderhistory-65765df1fc1f11e5974cd5203249f77a\\/order_store-orderhistory-ka-139517,].  32,011,749 bytes to 29,390,144 (~91% of original) in 1,771ms = 15.826440MB\\/s.  39,261 total partitions merged to 36,402.  Partition merge counts were {1:33543, 2:2859, }\" }\n{ \"source\" : \"cassandra\", \"message\": \"WARN  [ServiceThread] 2016-06-30 14:42:41,538  GCInspector.java:256 - G1 Young Generation GC in 202ms.  G1 Eden Space: 1157627904 -\u003e 0; G1 Old Gen: 6819034128 -\u003e 4151661080; G1 Survivor Space: 553648128 -\u003e 218103808;\" }\n{ \"source\" : \"cassandra\", \"message\": \"INFO  [ServiceThread] 2016-06-30 14:42:41,542  StatusLogger.java:99 - KeyCache                  365405196               1073741824                      all\" }\n{ \"source\" : \"cassandra\", \"message\": \"WARN  [ServiceThread] 2016-06-30 14:42:41,538  GCInspector.java:256 - whatever\" }\n{ \"source\" : \"cassandra\", \"message\": \"2016-06-30 14:42:41 [ServiceThread] WARN GCInspector.java:256 - whatever\" }\n{ \"source\" : \"cassandra\", \"message\": \"DEBUG [ValidationExecutor:108] 2016-06-30 14:42:41,538 EstimatedHistogram.java:304 - [0..0]: 1\" }\n{ \"source\" : \"cassandra\", \"message\": \"DEBUG [PerDiskMemtableFlushWriter_0:6272] 2019-02-11 16:22:18,428 Memtable.java:485 - Completed flushing \\/cassdata\\/system\\/batches-845e4cb463211234e12b64ff2c24a132\\/321-big-Data.db (17.861KiB) for commitlog position CommitLogPosition(segmentId=1539908174810, position=5726318)\" }\n{ \"source\" : \"cassandra\", \"message\": \"DEBUG [ScheduledTasks:1] 2018-11-22 12:50:31,441  MonitoringTask.java:173 - 3 operations were slow in the last 5000 msecs:\\n\u003cSELECT * FROM offernet.work_e WHERE community_id = 1496222336 AND member_id = 49 AND ~~edge_label_id = 65550 LIMIT 50000\u003e, time 505 msec - slow timeout 500 msec\\n\u003cSELECT * FROM offernet.item_e WHERE community_id = 2052914560 AND member_id = 189 AND ~~edge_label_id = 65553 LIMIT 50000\u003e, time 505 msec - slow timeout 500 msec\\n\u003cSELECT * FROM offernet.item_e WHERE community_id = 2140990336 AND member_id = 212 AND ~~edge_label_id = 65553 LIMIT 50000\u003e, time 504 msec - slow timeout 500 msec\\n\" }\n{ \"source\" : \"cassandra\", \"message\": \"DEBUG [ScheduledTasks:1] 2019-12-30 15:24:19,781 MonitoringTask.java:173 - 1 operations were slow in the last 5000 msecs:\\n\u003cSELECT * FROM system_schema.tables LIMIT 100\u003e, was slow 2 times: avg\\/min\\/max 2\\/2\\/3 msec - slow timeout 2 msec\\n\u003cSELECT * FROM system_schema.columns LIMIT 200\u003e, was slow 3 times: avg\\/min\\/max 4\\/5\\/6 msec - slow timeout 3 msec\\n\" }\n{ \"source\" : \"cassandra\", \"message\": \"TRACE [GossipStage:1] 2018-07-04 17:07:47,879 Gossiper.java:1234 - Updating heartbeat state version to 2344 from 2343 for 127.0.0.2:7000\" }\n{ \"source\" : \"cassandra\", \"message\": \"TRACE [SharedPool-Worker-1] 2016-02-05 19:44:00,154 Message.java:506 - Received: OPTIONS, v=4\" }\n{ \"source\" : \"cassandra\", \"message\": \"TRACE [SharedPool-Worker-1] 2016-02-05 19:44:09,346 Message.java:525 - Responding: ROWS [user_id(tlp_example, user_data), org.apache.cassandra.db.marshal.UUIDType][email(tlp_example, user_data), org.apache.cassandra.db.marshal.UTF8Type][tax_id(tlp_example, user_data), org.apache.cassandra.db.marshal.UTF8Type] | db8f7a00-cc3e-11e5-b248-091830ac5256 | nate+logex@thelastpickle.com | abc123 | 19be0e40-cc3f-11e5-b248-091830ac5256 | nate+logex@thelastpickle.com | abc123 ---, v=4\" }\n{ \"source\" : \"httpd\", \"message\": \"127.0.0.1 - frank [13\\/Jul\\/2016:10:55:36 +0000] \\\"GET \\/apache_pb.gif HTTP\\/1.0\\\" 200 2326\" }\n{ \"source\" : \"httpd\", \"message\": \"192.0.2.1 - Ultan [07\\/Mar\\/2004:16:43:54 -0800] \\\"GET \\/unencrypted_password_list?foo=bar HTTP\\/1.1\\\" 404 9001 \\\"http:\\/\\/passwords.hackz0r\\\" \\\"Mozilla\\/4.08 [en] (Win95)\\\"\" }\n{ \"source\" : \"azure.recoveryservices\", \"message\": \"{\\\"Authorization\\\":\\\"null\\\",\\\"Claims\\\":\\\"{\\\\\\\"http:\\/\\/schemas.xmlsoap.org\\/ws\\/2005\\/05\\/identityclaims\\/emailaddress\\\\\\\":\\\\\\\"Microsoft.RecoveryServices\\\\\\\"}\\\",\\\"correlationId\\\":\\\"1054d95a-7364-420e-a016-aceb8a4bb7dc\\\",\\\"DeploymentUnit\\\":\\\"cus-pod01-manag1-az01-testr\\\",\\\"durationMs\\\":0,\\\"EventId\\\":197,\\\"eventName\\\":\\\"Backup\\\",\\\"EventName\\\":\\\"AzureBackupActivityLog\\\",\\\"evt\\\":{\\\"category\\\":\\\"Administration\\\",\\\"name\\\":\\\"Microsoft.RecoveryServices\\\\\\/values\\\\\\/backupFabrics\\\\\\/protectionContainers\\\\\\/protectedItems\\\\\\/backup\\\\\\/action\\\",\\\"outcome\\\":\\\"Succeeded\\\"},\\\"identity\\\":\\\"{\\\\\\\"claims\\\\\\\":{\\\\\\\"http:\\/\\/schemas.xmlsoap.org\\/ws\\/2005\\/05\\/identityclaims\\/emailaddress\\\\\\\":\\\\\\\"Microsoft.RecoveryServices\\\\\\\"}}\\\",\\\"level\\\":\\\"Informational\\\",\\\"location\\\":\\\"centralus\\\",\\\"operationId\\\":\\\"6caea86d-3f4c-4c5f-b2ba-b53e502adb84\\\",\\\"operationVersion\\\":\\\"null\\\",\\\"properties\\\":{\\\"Entity Name\\\":\\\"test-6\\\",\\\"Job Id\\\":\\\"aa52fedc-8783-41a4-b285-39dd2f41cd2d\\\",\\\"Start Time\\\":\\\"2021-07-19 16:32:41Z\\\"},\\\"resourceId\\\":\\\"\\\\\\/SUBSCRIPTIONS\\\\\\/A4F42A47-2B5B-4A4C-B6CF-F00D6C189365\\\\\\/RESOURCEGROUPS\\\\\\/TESTRG\\\\\\/PROVIDERS\\\\\\/MICROSOFT.RECOVERYSERVICES\\\\\\/VAULTS\\\\\\/VAULT428\\\",\\\"Result Description\\\":\\\"Backup Succeeded\\\",\\\"service\\\":\\\"azure\\\",\\\"time\\\":\\\"2021-07-19T16:53:55.5361483Z\\\"}\" }\n{ \"source\" : \"csharp\", \"message\": \"{\\\"date\\\":\\\"2017-03-10T15:13:53.1302217+01:00\\\",\\\"level\\\":\\\"INFO\\\",\\\"appname\\\":\\\"ConsoleApplication1.vshost.exe\\\",\\\"logger\\\":\\\"ConsoleApplication1.Program\\\",\\\"thread\\\":\\\"10\\\",\\\"message\\\":\\\"A calculation is about to start: 10x5\\\"}\" }\n{ \"source\" : \"csharp\", \"message\": \"2016-09-02T15:02:29.648Z INFO this is my message\" }\n{ \"source\" : \"csharp\", \"message\": \"2016-05-24 15:53:35.7175 INFO this my my log example\" }\n{ \"source\" : \"csharp\", \"message\": \"2017-03-10 15:13:53.130 ERROR [10] ConsoleApplication1.Program mymethod:32 - an error occured while processing\" }\n{ \"source\" : \"csharp\", \"message\": \"2019-10-24 19:58:29,582 [1] INFO  Log4NetExample.Program [(null)] {order-number=1024, log4net:UserName=NOT AVAILABLE, dd.span_id=\\\"1413846021656668177\\\", log4net:HostName=LAPTOP-KUAFQR15, log4net:Identity=NOT AVAILABLE, dd.trace_id=\\\"4603319493700240667\\\"} - Message example\" }\n{ \"source\" : \"csharp\", \"message\": \"{\\\"@t\\\":\\\"2019-10-24T21:27:13.8349907Z\\\",\\\"@mt\\\":\\\"Message inside a trace.\\\",\\\"dd.span_id\\\":\\\"5142026215797304283\\\",\\\"dd.trace_id\\\":\\\"4878079399117499473\\\",\\\"order-number\\\":1024}\" }\n{ \"source\" : \"csharp\", \"message\": \"{\\\"MessageTemplate\\\":\\\"Processed {@Position} in {Elapsed:000} ms.\\\",\\\"Level\\\":\\\"Information\\\",\\\"Timestamp\\\":\\\"2016-09-02T15:02:29.648Z\\\",\\\"Renderings\\\":{\\\"Elapsed\\\":[{\\\"Format\\\":\\\"000\\\",\\\"Rendering\\\":\\\"034\\\"}]},\\\"RenderedMessage\\\":\\\"Processed { Latitude: 25, Longitude: 134 } in 034 ms.\\\",\\\"Properties\\\":{\\\"Position\\\":{\\\"Latitude\\\":25,\\\"Longitude\\\":134},\\\"Elapsed\\\":34}}\" }\n{ \"source\" : \"csharp\", \"message\": \"{\\\"@t\\\":\\\"2020-05-20T04:15:28.6898801Z\\\",\\\"@m\\\":\\\"Processed { Latitude: 25, Longitude: 134 } in 034 ms.\\\",\\\"@i\\\":\\\"d1eb2146\\\",\\\"Position\\\":{\\\"Latitude\\\":25,\\\"Longitude\\\":134},\\\"Elapsed\\\":34}\" }\n{ \"source\" : \"csharp\", \"message\": \"{\\\"@t\\\":\\\"2020-10-08T22:57:43.6528621Z\\\",\\\"@m\\\":\\\"Entered Home\\/Index action\\\",\\\"SourceContext\\\":\\\"AspNetCoreWithSerilog.Controllers.HomeController\\\",\\\"RequestPath\\\":\\\"\\/\\\",\\\"dd_span_id\\\":\\\"1716695354597411619\\\",\\\"dd_trace_id\\\":\\\"6500362470500556863\\\",\\\"dd_version\\\":\\\"1.0.0\\\",\\\"dd_service\\\":\\\"AspNetCoreWithSerilog\\\",\\\"dd_env\\\":\\\"Development\\\"}\" }\n{ \"source\" : \"csharp\", \"message\": \"2019-11-25 11:21:32.6282|INFO|NLogExample.Program|{dd.trace_id=\\\"4424326124026709723\\\", dd.span_id=\\\"249969541933646857\\\"} Message during a trace.\" }\n{ \"source\" : \"csharp\", \"message\": \"2019-12-02 11:47:20.467 -08:00 [INF] { dd.span_id: \\\"4014120331748607290\\\", dd.trace_id: \\\"2762343115747197096\\\", order-number: 1024 } Message during a trace.\" }\n{ \"source\" : \"csharp\", \"message\": \"2019-12-02 11:47:20.467 -08:00 [INF] { dd.service: excelsior dd.env: prod dd.version=abc123 dd.span_id: \\\"4014120331748607290\\\", dd.trace_id: \\\"2762343115747197096\\\", order-number: 1024 } Message during a trace.\" }\n{ \"source\" : \"csharp\", \"message\": \"2019-11-25 11:21:32.6282|INFO|NLogExample.Program|{dd.service=excelsior dd.env=prod dd.version=abc123 dd.trace_id=\\\"4424326124026709723\\\", dd.span_id=\\\"249969541933646857\\\"} Message during a trace.\" }\n{ \"source\" : \"csharp\", \"message\": \"2019-10-24 19:58:29,582 [1] INFO  Log4NetExample.Program [(null)] {order-number=1024, log4net:UserName=NOT AVAILABLE, dd.span_id=\\\"1413846021656668177\\\", dd.service=excelsior, dd.env=prod, dd.version=abc123, log4net:HostName=LAPTOP-KUAFQR15, log4net:Identity=NOT AVAILABLE, dd.trace_id=\\\"4603319493700240667\\\"} - Message example\" }\n{ \"source\" : \"csharp\", \"message\": \"{\\\"@t\\\":\\\"2019-10-24T21:27:13.8349907Z\\\",\\\"@m\\\":\\\"Message inside a trace.\\\",\\\"@mt\\\":\\\"this is the message template\\\",\\\"dd.span_id\\\":\\\"5142026215797304283\\\",\\\"dd.trace_id\\\":\\\"4878079399117499473\\\",\\\"order-number\\\":1024,\\\"@l\\\":\\\"Error\\\"}\" }\n{ \"source\" : \"browser\", \"message\": \"{\\\"http\\\":{\\\"url\\\":\\\"\\/datadoghq\\/company?test=var1%20Pl\\\",\\\"useragent\\\":\\\"Mozilla\\/5.0 (X11; Linux x86_64) AppleWebKit\\/537.36 (KHTML, like Gecko) Chrome\\/55.0.2883.87 Safari\\/537.36\\\"},\\\"message\\\":\\\"Button Clicked\\\",\\\"name\\\":\\\"registerButton\\\",\\\"network\\\":{\\\"client\\\":{\\\"ip\\\":\\\"172.17.0.1\\\"}}}\" }\n{ \"source\" : \"browser\", \"message\": \"{\\t\\\"message\\\": \\\"Browser Log Collector started and logging debug logs to http\\\",\\t\\\"agent\\\": \\\"browserLogCollector\\\",\\t\\\"datadog_version\\\": \\\"35.1859776\\\",\\t\\\"session_id\\\": \\\"20cdb46b-eb38-48c8-8037-baa19b188f1e\\\",\\t\\\"http\\\": {\\t\\t\\\"referer\\\": \\\"https:\\/\\/app.datadoghq.com\\/account\\/team\\\",\\t\\t\\\"useragent\\\": \\\"Mozilla\\/5.0 (Windows NT 10.0; Win64; x64; rv:70.0) Gecko\\/20100101 Firefox\\/70.0\\\"\\t},\\t\\\"datadog_version_number\\\": 1859776,\\t\\\"network\\\": {\\t\\t\\\"client\\\": {\\t\\t\\t\\\"ip\\\": \\\"81.175.170.234\\\"\\t\\t}\\t},\\t\\\"status\\\": \\\"info\\\",\\t\\\"date\\\": 1573031676010,\\t\\\"view\\\": {\\t\\t\\\"referrer\\\": \\\"https:\\/\\/app.datadoghq.com\\/account\\/profile\\\",\\t\\t\\\"id\\\": \\\"9252b1eb-5910-4f6f-9b09-a6cb76609be3\\\",\\t\\t\\\"url\\\": \\\"https:\\/\\/app.datadoghq.com\\/account\\/team\\\"\\t},\\t\\\"sessionId\\\": \\\"20cdb46b-eb38-48c8-8037-baa19b188f1e\\\",\\t\\\"application_id\\\": \\\"ac8218cf-498b-4d33-bd44-151095959547\\\",\\t\\\"browser_test\\\": false}\" }\n"
            },
            "id": "soak/lading-http-gen-bootstrap",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "lading-http-gen-bootstrap",
                "namespace": "soak",
                "resource_version": "525",
                "uid": "243511cc-0273-41a8-bcb6-a4fc83a3eaf3"
              }
            ]
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kubernetes_namespace.soak",
            "module.vector.kubernetes_config_map.vector",
            "module.vector.kubernetes_deployment.vector",
            "module.vector.kubernetes_service.vector"
          ]
        }
      ]
    },
    {
      "module": "module.http-gen",
      "mode": "managed",
      "type": "kubernetes_deployment",
      "name": "http-gen",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "id": "soak/http-gen",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 1,
                "labels": {
                  "app": "http-gen",
                  "type": "comparison"
                },
                "name": "http-gen",
                "namespace": "soak",
                "resource_version": "558",
                "uid": "a53fea48-00eb-42ac-a880-c25e7ac2ffc8"
              }
            ],
            "spec": [
              {
                "min_ready_seconds": 0,
                "paused": false,
                "progress_deadline_seconds": 600,
                "replicas": "1",
                "revision_history_limit": 10,
                "selector": [
                  {
                    "match_expressions": [],
                    "match_labels": {
                      "app": "http-gen",
                      "type": "comparison"
                    }
                  }
                ],
                "strategy": [
                  {
                    "rolling_update": [
                      {
                        "max_surge": "25%",
                        "max_unavailable": "25%"
                      }
                    ],
                    "type": "RollingUpdate"
                  }
                ],
                "template": [
                  {
                    "metadata": [
                      {
                        "annotations": {
                          "prometheus.io/path": "/metrics",
                          "prometheus.io/port": "9090",
                          "prometheus.io/scrape": "true"
                        },
                        "generate_name": "",
                        "generation": 0,
                        "labels": {
                          "app": "http-gen",
                          "type": "comparison"
                        },
                        "name": "",
                        "namespace": "",
                        "resource_version": "",
                        "uid": ""
                      }
                    ],
                    "spec": [
                      {
                        "active_deadline_seconds": 0,
                        "affinity": [],
                        "automount_service_account_token": false,
                        "container": [
                          {
                            "args": null,
                            "command": [
                              "/http_gen"
                            ],
                            "env": [],
                            "env_from": [],
                            "image": "ghcr.io/blt/lading:sha-0da91906d56acc899b829cea971d79f13e712e21",
                            "image_pull_policy": "IfNotPresent",
                            "lifecycle": [],
                            "liveness_probe": [
                              {
                                "exec": [],
                                "failure_threshold": 3,
                                "http_get": [
                                  {
                                    "host": "",
                                    "http_header": [],
                                    "path": "/metrics",
                                    "port": "9090",
                                    "scheme": "HTTP"
                                  }
                                ],
                                "initial_delay_seconds": 0,
                                "period_seconds": 10,
                                "success_threshold": 1,
                                "tcp_socket": [],
                                "timeout_seconds": 1
                              }
                            ],
                            "name": "http-gen",
                            "port": [
                              {
                                "container_port": 9090,
                                "host_ip": "",
                                "host_port": 0,
                                "name": "prom-export",
                                "protocol": "TCP"
                              }
                            ],
                            "readiness_probe": [],
                            "resources": [
                              {
                                "limits": {
                                  "cpu": "1",
                                  "memory": "512Mi"
                                },
                                "requests": {
                                  "cpu": "1",
                                  "memory": "512Mi"
                                }
                              }
                            ],
                            "security_context": [],
                            "startup_probe": [],
                            "stdin": false,
                            "stdin_once": false,
                            "termination_message_path": "/dev/termination-log",
                            "termination_message_policy": "File",
                            "tty": false,
                            "volume_mount": [
                              {
                                "mount_path": "/data",
                                "mount_propagation": "None",
                                "name": "data",
                                "read_only": true,
                                "sub_path": ""
                              },
                              {
                                "mount_path": "/etc/lading",
                                "mount_propagation": "None",
                                "name": "etc-lading",
                                "read_only": true,
                                "sub_path": ""
                              }
                            ],
                            "working_dir": ""
                          }
                        ],
                        "dns_config": [],
                        "dns_policy": "ClusterFirst",
                        "enable_service_links": true,
                        "host_aliases": [],
                        "host_ipc": false,
                        "host_network": false,
                        "host_pid": false,
                        "hostname": "",
                        "image_pull_secrets": [],
                        "init_container": [],
                        "node_name": "",
                        "node_selector": null,
                        "priority_class_name": "",
                        "readiness_gate": [],
                        "restart_policy": "Always",
                        "security_context": [],
                        "service_account_name": "",
                        "share_process_namespace": false,
                        "subdomain": "",
                        "termination_grace_period_seconds": 30,
                        "toleration": [],
                        "topology_spread_constraint": [],
                        "volume": [
                          {
                            "aws_elastic_block_store": [],
                            "azure_disk": [],
                            "azure_file": [],
                            "ceph_fs": [],
                            "cinder": [],
                            "config_map": [
                              {
                                "default_mode": "0644",
                                "items": [],
                                "name": "lading-http-gen",
                                "optional": false
                              }
                            ],
                            "csi": [],
                            "downward_api": [],
                            "empty_dir": [],
                            "fc": [],
                            "flex_volume": [],
                            "flocker": [],
                            "gce_persistent_disk": [],
                            "git_repo": [],
                            "glusterfs": [],
                            "host_path": [],
                            "iscsi": [],
                            "local": [],
                            "name": "etc-lading",
                            "nfs": [],
                            "persistent_volume_claim": [],
                            "photon_persistent_disk": [],
                            "projected": [],
                            "quobyte": [],
                            "rbd": [],
                            "secret": [],
                            "vsphere_volume": []
                          },
                          {
                            "aws_elastic_block_store": [],
                            "azure_disk": [],
                            "azure_file": [],
                            "ceph_fs": [],
                            "cinder": [],
                            "config_map": [
                              {
                                "default_mode": "0644",
                                "items": [],
                                "name": "lading-http-gen-bootstrap",
                                "optional": false
                              }
                            ],
                            "csi": [],
                            "downward_api": [],
                            "empty_dir": [],
                            "fc": [],
                            "flex_volume": [],
                            "flocker": [],
                            "gce_persistent_disk": [],
                            "git_repo": [],
                            "glusterfs": [],
                            "host_path": [],
                            "iscsi": [],
                            "local": [],
                            "name": "data",
                            "nfs": [],
                            "persistent_volume_claim": [],
                            "photon_persistent_disk": [],
                            "projected": [],
                            "quobyte": [],
                            "rbd": [],
                            "secret": [],
                            "vsphere_volume": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            ],
            "timeouts": null,
            "wait_for_rollout": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6NjAwMDAwMDAwMDAwLCJ1cGRhdGUiOjYwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9",
          "dependencies": [
            "kubernetes_namespace.soak",
            "module.http-gen.kubernetes_config_map.lading",
            "module.http-gen.kubernetes_config_map.lading_bootstrap",
            "module.vector.kubernetes_config_map.vector",
            "module.vector.kubernetes_deployment.vector",
            "module.vector.kubernetes_service.vector"
          ]
        }
      ]
    },
    {
      "module": "module.http-gen",
      "mode": "managed",
      "type": "kubernetes_service",
      "name": "http-gen",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "id": "soak/http-gen",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "http-gen",
                "namespace": "soak",
                "resource_version": "527",
                "uid": "eb4e8f07-76bb-4db1-8836-877cd62289c5"
              }
            ],
            "spec": [
              {
                "cluster_ip": "10.103.36.183",
                "external_ips": null,
                "external_name": "",
                "external_traffic_policy": "",
                "health_check_node_port": 0,
                "load_balancer_ip": "",
                "load_balancer_source_ranges": null,
                "port": [
                  {
                    "name": "prom-export",
                    "node_port": 0,
                    "port": 9090,
                    "protocol": "TCP",
                    "target_port": "9090"
                  }
                ],
                "publish_not_ready_addresses": false,
                "selector": {
                  "app": "http-gen",
                  "type": "comparison"
                },
                "session_affinity": "ClientIP",
                "type": "ClusterIP"
              }
            ],
            "status": [
              {
                "load_balancer": [
                  {
                    "ingress": []
                  }
                ]
              }
            ],
            "timeouts": null,
            "wait_for_load_balancer": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDB9LCJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "kubernetes_namespace.soak",
            "module.vector.kubernetes_config_map.vector",
            "module.vector.kubernetes_deployment.vector",
            "module.vector.kubernetes_service.vector"
          ]
        }
      ]
    },
    {
      "module": "module.monitoring",
      "mode": "data",
      "type": "template_file",
      "name": "soak-observer",
      "provider": "provider[\"registry.terraform.io/hashicorp/template\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "filename": null,
            "id": "68c3501af92baea5e61ea6c39901136f096ea59b826e32d71c503e31ace9e5f8",
            "rendered": "experiment_name: \"http_pipelines_blackhole_acks\"\nvariant: \"comparison\"\ncapture_path: \"/captures/comparison.captures\"\ntargets:\n  - id: vector\n    url: \"http://vector.soak:9090/metrics\"\n  - id: lading_http_gen\n    url: \"http://http-gen.soak:9090\"\n  - id: lading_http_blackhole\n    url: \"http://http-blackhole.soak:9090\"\n  - id: lading_tcp_gen\n    url: \"http://tcp-gen.soak:9090\"\n  - id: lading_splunk_hec_blackhole\n    url: \"http://splunk-hec-blackhole.soak:9090\"\n  - id: lading_splunk_hec_gen\n    url: \"http://splunk-hec-gen.soak:9090\"\n",
            "template": "experiment_name: \"${experiment_name}\"\nvariant: \"${experiment_variant}\"\ncapture_path: \"/captures/${experiment_variant}.captures\"\ntargets:\n  - id: vector\n    url: \"http://vector.soak:9090/metrics\"\n  - id: lading_http_gen\n    url: \"http://http-gen.soak:9090\"\n  - id: lading_http_blackhole\n    url: \"http://http-blackhole.soak:9090\"\n  - id: lading_tcp_gen\n    url: \"http://tcp-gen.soak:9090\"\n  - id: lading_splunk_hec_blackhole\n    url: \"http://splunk-hec-blackhole.soak:9090\"\n  - id: lading_splunk_hec_gen\n    url: \"http://splunk-hec-gen.soak:9090\"\n",
            "vars": {
              "experiment_name": "http_pipelines_blackhole_acks",
              "experiment_variant": "comparison",
              "vector_id": "vector:6a71553d1e2d49501f03e40ce78090934fcfab13"
            }
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "module": "module.monitoring",
      "mode": "managed",
      "type": "kubernetes_config_map",
      "name": "observer",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "binary_data": null,
            "data": {
              "observer.yaml": "experiment_name: \"http_pipelines_blackhole_acks\"\nvariant: \"comparison\"\ncapture_path: \"/captures/comparison.captures\"\ntargets:\n  - id: vector\n    url: \"http://vector.soak:9090/metrics\"\n  - id: lading_http_gen\n    url: \"http://http-gen.soak:9090\"\n  - id: lading_http_blackhole\n    url: \"http://http-blackhole.soak:9090\"\n  - id: lading_tcp_gen\n    url: \"http://tcp-gen.soak:9090\"\n  - id: lading_splunk_hec_blackhole\n    url: \"http://splunk-hec-blackhole.soak:9090\"\n  - id: lading_splunk_hec_gen\n    url: \"http://splunk-hec-gen.soak:9090\"\n"
            },
            "id": "monitoring/observer",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "observer",
                "namespace": "monitoring",
                "resource_version": "458",
                "uid": "fe5d9cd9-d43f-48f7-af03-acf577ae8c92"
              }
            ]
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "module.monitoring.data.template_file.soak-observer",
            "module.monitoring.kubernetes_namespace.monitoring"
          ]
        }
      ]
    },
    {
      "module": "module.monitoring",
      "mode": "managed",
      "type": "kubernetes_deployment",
      "name": "observer",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "id": "monitoring/observer",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 1,
                "labels": {
                  "app": "observer"
                },
                "name": "observer",
                "namespace": "monitoring",
                "resource_version": "534",
                "uid": "51439a0f-1234-420d-b3ac-9e4e36a2eac6"
              }
            ],
            "spec": [
              {
                "min_ready_seconds": 0,
                "paused": false,
                "progress_deadline_seconds": 600,
                "replicas": "1",
                "revision_history_limit": 10,
                "selector": [
                  {
                    "match_expressions": [],
                    "match_labels": {
                      "app": "observer"
                    }
                  }
                ],
                "strategy": [
                  {
                    "rolling_update": [
                      {
                        "max_surge": "25%",
                        "max_unavailable": "25%"
                      }
                    ],
                    "type": "RollingUpdate"
                  }
                ],
                "template": [
                  {
                    "metadata": [
                      {
                        "annotations": null,
                        "generate_name": "",
                        "generation": 0,
                        "labels": {
                          "app": "observer"
                        },
                        "name": "",
                        "namespace": "",
                        "resource_version": "",
                        "uid": ""
                      }
                    ],
                    "spec": [
                      {
                        "active_deadline_seconds": 0,
                        "affinity": [],
                        "automount_service_account_token": false,
                        "container": [
                          {
                            "args": [
                              "--config-path",
                              "/etc/vector/soak/observer.yaml"
                            ],
                            "command": null,
                            "env": [],
                            "env_from": [],
                            "image": "ghcr.io/vectordotdev/vector/soak-observer:sha-64c5a94c2187581b93705e168a72d0f0a05325dc",
                            "image_pull_policy": "IfNotPresent",
                            "lifecycle": [],
                            "liveness_probe": [],
                            "name": "observer",
                            "port": [],
                            "readiness_probe": [],
                            "resources": [
                              {
                                "limits": {
                                  "cpu": "100m",
                                  "memory": "32Mi"
                                },
                                "requests": {
                                  "cpu": "100m",
                                  "memory": "32Mi"
                                }
                              }
                            ],
                            "security_context": [],
                            "startup_probe": [],
                            "stdin": false,
                            "stdin_once": false,
                            "termination_message_path": "/dev/termination-log",
                            "termination_message_policy": "File",
                            "tty": false,
                            "volume_mount": [
                              {
                                "mount_path": "/captures",
                                "mount_propagation": "None",
                                "name": "captures",
                                "read_only": false,
                                "sub_path": ""
                              },
                              {
                                "mount_path": "/etc/vector/soak",
                                "mount_propagation": "None",
                                "name": "observer-config",
                                "read_only": true,
                                "sub_path": ""
                              }
                            ],
                            "working_dir": ""
                          }
                        ],
                        "dns_config": [],
                        "dns_policy": "ClusterFirst",
                        "enable_service_links": true,
                        "host_aliases": [],
                        "host_ipc": false,
                        "host_network": false,
                        "host_pid": false,
                        "hostname": "",
                        "image_pull_secrets": [],
                        "init_container": [],
                        "node_name": "",
                        "node_selector": null,
                        "priority_class_name": "",
                        "readiness_gate": [],
                        "restart_policy": "Always",
                        "security_context": [],
                        "service_account_name": "",
                        "share_process_namespace": false,
                        "subdomain": "",
                        "termination_grace_period_seconds": 30,
                        "toleration": [],
                        "topology_spread_constraint": [],
                        "volume": [
                          {
                            "aws_elastic_block_store": [],
                            "azure_disk": [],
                            "azure_file": [],
                            "ceph_fs": [],
                            "cinder": [],
                            "config_map": [],
                            "csi": [],
                            "downward_api": [],
                            "empty_dir": [],
                            "fc": [],
                            "flex_volume": [],
                            "flocker": [],
                            "gce_persistent_disk": [],
                            "git_repo": [],
                            "glusterfs": [],
                            "host_path": [
                              {
                                "path": "/captures",
                                "type": ""
                              }
                            ],
                            "iscsi": [],
                            "local": [],
                            "name": "captures",
                            "nfs": [],
                            "persistent_volume_claim": [],
                            "photon_persistent_disk": [],
                            "projected": [],
                            "quobyte": [],
                            "rbd": [],
                            "secret": [],
                            "vsphere_volume": []
                          },
                          {
                            "aws_elastic_block_store": [],
                            "azure_disk": [],
                            "azure_file": [],
                            "ceph_fs": [],
                            "cinder": [],
                            "config_map": [
                              {
                                "default_mode": "0644",
                                "items": [],
                                "name": "observer",
                                "optional": false
                              }
                            ],
                            "csi": [],
                            "downward_api": [],
                            "empty_dir": [],
                            "fc": [],
                            "flex_volume": [],
                            "flocker": [],
                            "gce_persistent_disk": [],
                            "git_repo": [],
                            "glusterfs": [],
                            "host_path": [],
                            "iscsi": [],
                            "local": [],
                            "name": "observer-config",
                            "nfs": [],
                            "persistent_volume_claim": [],
                            "photon_persistent_disk": [],
                            "projected": [],
                            "quobyte": [],
                            "rbd": [],
                            "secret": [],
                            "vsphere_volume": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            ],
            "timeouts": null,
            "wait_for_rollout": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6NjAwMDAwMDAwMDAwLCJ1cGRhdGUiOjYwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9",
          "dependencies": [
            "module.monitoring.data.template_file.soak-observer",
            "module.monitoring.kubernetes_config_map.observer",
            "module.monitoring.kubernetes_namespace.monitoring"
          ]
        }
      ]
    },
    {
      "module": "module.monitoring",
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "monitoring",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "monitoring",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "monitoring",
                "resource_version": "449",
                "uid": "45d96a8f-de7e-4011-8f34-668889c9d703"
              }
            ],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ=="
        }
      ]
    },
    {
      "module": "module.vector",
      "mode": "managed",
      "type": "kubernetes_config_map",
      "name": "vector",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "binary_data": null,
            "data": {
              "vector.toml": "data_dir = \"/var/lib/vector\"\n\n##\n## Sources\n##\n\n[sources.internal_metrics]\ntype = \"internal_metrics\"\n\n[sources.logs]\ntype = \"http\"\naddress = \"0.0.0.0:8282\"\nencoding = \"text\"\nacknowledgements = true\n\n##\n## Transforms\n##\n\n[transforms.preprocessing]\ntype = \"remap\"\ninputs = [\"logs\"]\nsource = '''\n., err = parse_json(.message)\n.custom = {}\n'''\n\n[transforms.processing]\ntype = \"pipelines\"\ninputs = [\"preprocessing\"]\n\n[transforms.processing.logs]\norder = [\n    \"nginx\",\n    \"redis\",\n    \"consul\",\n    \"python\",\n    \"rabbitmq\",\n    \"zookeeper\",\n    \"elasticsearch\",\n    \"kafka\",\n    \"couchdb\",\n    \"docker\",\n    \"datadog_agent\",\n    \"ruby\",\n    \"vault\",\n    \"nginx_ingress_controller\",\n    \"mysql\",\n    \"kubernetes_cluster_autoscaler\",\n    \"aws_alb_ingress_controller\",\n    \"proxysql\",\n    \"azure\",\n    \"azure_web\",\n    \"azure_storage\",\n    \"azure_network\",\n    \"azure_compute\",\n    \"etcd\",\n    \"glog_pipeline\",\n    \"auth0\",\n    \"kube_scheduler__glog_\",\n    \"aws_ecs_agent\",\n    \"nodejs\",\n    \"postgresql\",\n    \"cassandra\",\n    \"apache_httpd\",\n    \"azure_recovery_services\",\n    \"c_\",\n    \"web_browser_logs\",\n]\n\n[transforms.processing.logs.pipelines.nginx]\nname = \"nginx\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:nginx\"\n\n[[transforms.processing.logs.pipelines.nginx.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_client_ip} %{_ident} %{_auth} \\\\[%{_date_access}\\\\] \\\"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\\\" %{_status_code} (?\u003e%{_bytes_written}|-)\",\"%{access.common} (%{number:duration:scale(1000000000)} )?\\\"%{_referer}\\\" \\\"%{_user_agent}\\\"( \\\"%{_x_forwarded_for}\\\")?.*\",\"%{date(\\\"yyyy/MM/dd HH:mm:ss\\\"):date_access} \\\\[%{word:level}\\\\] %{data:error.message}(, %{data})?\"],\naliases: {\n\"access.common\": \"%{_client_ip} %{_ident} %{_auth} \\\\[%{_date_access}\\\\] \\\"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\\\" %{_status_code} (?\u003e%{_bytes_written}|-)\",\n\"access.combined\": \"%{access.common} (%{number:duration:scale(1000000000)} )?\\\"%{_referer}\\\" \\\"%{_user_agent}\\\"( \\\"%{_x_forwarded_for}\\\")?.*\",\n\"error.format\": \"%{date(\\\"yyyy/MM/dd HH:mm:ss\\\"):date_access} \\\\[%{word:level}\\\\] %{data:error.message}(, %{data})?\",\n\"_auth\": \"%{notSpace:http.auth:nullIf(\\\"-\\\")}\",\n\"_bytes_written\": \"%{integer:network.bytes_written}\",\n\"_client_ip\": \"%{ipOrHost:network.client.ip}\",\n\"_version\": \"HTTP\\\\/%{regex(\\\"\\\\\\\\d+\\\\\\\\.\\\\\\\\d+\\\"):http.version}\",\n\"_url\": \"%{notSpace:http.url}\",\n\"_ident\": \"%{notSpace:http.ident:nullIf(\\\"-\\\")}\",\n\"_user_agent\": \"%{regex(\\\"[^\\\\\\\\\\\\\\\"]*\\\"):http.useragent}\",\n\"_referer\": \"%{notSpace:http.referer}\",\n\"_status_code\": \"%{integer:http.status_code}\",\n\"_method\": \"%{word:http.method}\",\n\"_date_access\": \"%{date(\\\"dd/MMM/yyyy:HH:mm:ss Z\\\"):date_access}\",\n\"_x_forwarded_for\": \"%{regex(\\\"[^\\\\\\\\\\\\\\\"]*\\\"):http._x_forwarded_for:nullIf(\\\"-\\\")}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.nginx.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.client) {\n.custom.network.client.ip = .custom.client\n}\n'''\n\n[[transforms.processing.logs.pipelines.nginx.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .request,\npatterns: [\"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\"],\naliases: {\n\"request_parsing\": \"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\",\n\"_method\": \"%{word:http.method}\",\n\"_url\": \"%{notSpace:http.url}\",\n\"_version\": \"HTTP\\\\/%{regex(\\\"\\\\\\\\d+\\\\\\\\.\\\\\\\\d+\\\"):http.version}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.nginx.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_url(.custom.http.url); err == null) {\n  .custom.http.url_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.nginx.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_user_agent(.custom.http.useragent); err == null) {\n  .custom.http.useragent_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.nginx.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.date_access) {\n.timestamp = .custom.date_access\n}\n'''\n\n[[transforms.processing.logs.pipelines.nginx.transforms]]\ntype = \"remap\"\nsource = '''\nif match_datadog_query(., \"@http.status_code:[200 TO 299]\") {\n.custom.http.status_category = \"OK\"\n} else if match_datadog_query(., \"@http.status_code:[300 TO 399]\") {\n.custom.http.status_category = \"notice\"\n} else if match_datadog_query(., \"@http.status_code:[400 TO 499]\") {\n.custom.http.status_category = \"warning\"\n} else if match_datadog_query(., \"@http.status_code:[500 TO 599]\") {\n.custom.http.status_category = \"error\"\n}\n'''\n\n[[transforms.processing.logs.pipelines.nginx.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.http.status_category) ?? string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[transforms.processing.logs.pipelines.redis]\nname = \"redis\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:redis\"\n\n[[transforms.processing.logs.pipelines.redis.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_pid}:%{_role} %{_date} %{_severity} %{data:message}\"],\naliases: {\n\"default_format\": \"%{_pid}:%{_role} %{_date} %{_severity} %{data:message}\",\n\"_date\": \"(%{date(\\\"dd MMM HH:mm:ss.SSS\\\"):date}|%{date(\\\"dd MMM yyyy HH:mm:ss.SSS\\\"):date})\",\n\"_pid\": \"%{integer:pid}\",\n\"_severity\": \"%{notSpace:severity}\",\n\"_role\": \"%{word:role}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.redis.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.date) {\n.timestamp = .custom.date\n}\n'''\n\n[[transforms.processing.logs.pipelines.redis.transforms]]\ntype = \"remap\"\nsource = '''\nif match_datadog_query(., \"@severity: \\\".\\\"\") {\n.custom.redis.severity = \"debug\"\n} else if match_datadog_query(., \"@severity: \\\"-\\\"\") {\n.custom.redis.severity = \"verbose\"\n} else if match_datadog_query(., \"@severity: \\\"*\\\"\") {\n.custom.redis.severity = \"notice\"\n} else if match_datadog_query(., \"@severity: \\\"#\\\"\") {\n.custom.redis.severity = \"warning\"\n}\n'''\n\n[[transforms.processing.logs.pipelines.redis.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.redis.severity) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[transforms.processing.logs.pipelines.consul]\nname = \"consul\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:consul\"\n\n[[transforms.processing.logs.pipelines.consul.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"==\u003e\\\\s+(?\u003e%{_status}:|)%{data:message}\",\"(\\\\s*|\\\\t*)%{_date_2} %{_hostname} %{_app}\\\\[%{_thread_id}]:\\\\s+%{data:message}\",\"(\\\\s*|\\\\t*)(%{_date}|%{_date_3}) \\\\[%{_status}\\\\] %{_app}:( %{_event}:)?%{data:message}\"],\naliases: {\n\"Upstart_format\": \"==\u003e\\\\s+(?\u003e%{_status}:|)%{data:message}\",\n\"Consul_template\": \"(\\\\s*|\\\\t*)%{_date_2} %{_hostname} %{_app}\\\\[%{_thread_id}]:\\\\s+%{data:message}\",\n\"Default_format\": \"(\\\\s*|\\\\t*)(%{_date}|%{_date_3}) \\\\[%{_status}\\\\] %{_app}:( %{_event}:)?%{data:message}\",\n\"_date\": \"%{date(\\\"yyyy/MM/dd HH:mm:ss\\\"):timestamp}\",\n\"_date_2\": \"%{date(\\\"MMM dd HH:mm:ss\\\"):timestamp}\",\n\"_date_3\": \"%{date(\\\"yyyy-MM-dd'T'HH:mm:ss.SSSZZ\\\"):timestamp}\",\n\"_status\": \"%{word:level}\",\n\"_app\": \"%{data:app}\",\n\"_event\": \"%{word:event}\",\n\"_hostname\": \"%{notSpace:hostname}\",\n\"_thread_id\": \"%{integer:logger.thread.id}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.consul.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.consul.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[transforms.processing.logs.pipelines.python]\nname = \"python\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:python\"\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"(%{_python_prefix}|%{_datadog_prefix})\\\\s+%{data}Traceback \\\\(most recent call last\\\\):\\\\s*%{data:error.stack}\",\"(%{_python_prefix}|%{_datadog_prefix})\\\\s+%{data}\",\"%{date(\\\"yyyy-MM-dd'T'HH:mm:ss','SSS\\\"):timestamp}\\\\s+%{word:levelname}\\\\s+%{data}((\\\\n|\\\\t)%{data:error.stack})?\"],\naliases: {\n\"traceback_format\": \"(%{_python_prefix}|%{_datadog_prefix})\\\\s+%{data}Traceback \\\\(most recent call last\\\\):\\\\s*%{data:error.stack}\",\n\"python_format\": \"(%{_python_prefix}|%{_datadog_prefix})\\\\s+%{data}\",\n\"python_fallback\": \"%{date(\\\"yyyy-MM-dd'T'HH:mm:ss','SSS\\\"):timestamp}\\\\s+%{word:levelname}\\\\s+%{data}((\\\\n|\\\\t)%{data:error.stack})?\",\n\"_datadog_prefix\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss,SSS\\\"):timestamp} %{word:levelname}\\\\s+\\\\[%{notSpace:process.name}\\\\]\\\\s+\\\\[%{notSpace:filename}:%{number:lineno}\\\\]\\\\s+\\\\[%{data}dd.trace_id=%{word:dd.trace_id} dd.span_id=%{word:dd.span_id}\\\\] -\",\n\"_python_prefix\": \"%{date(\\\"yyyy-MM-dd'T'HH:mm:ss','SSS\\\"):timestamp}\\\\s+%{word:levelname}\\\\s+\\\\[%{notSpace:process.name}\\\\]\\\\s+\\\\[%{integer:process.id}\\\\]\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.levelname) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.traceback) {\n.custom.error.stack = .custom.traceback\n}\n'''\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.name) {\n.custom.logger.name = .custom.name\n}\n'''\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.threadName) {\n.custom.logger.thread_name = .custom.threadName\n}\n'''\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .error.stack,\npatterns: [\"File \\\"%{notSpace:filename}\\\", line %{integer:lineno}.*\\\\s+%{regex(\\\"[a-zA-Z]*Error[a-zA-Z]*\\\"):error.kind}: %{data:error.message}\"],\naliases: {\n\"parsing_traceback\": \"File \\\"%{notSpace:filename}\\\", line %{integer:lineno}.*\\\\s+%{regex(\\\"[a-zA-Z]*Error[a-zA-Z]*\\\"):error.kind}: %{data:error.message}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.trace_id) {\n.trace_id = .custom.dd.trace_id\n}\n'''\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.env) {\n.custom.env = .custom.dd.env\n}\n'''\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.version) {\n.custom.version = .custom.dd.version\n}\n'''\n\n[[transforms.processing.logs.pipelines.python.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.service) {\n.service = .custom.dd.service\n}\n'''\n\n[transforms.processing.logs.pipelines.rabbitmq]\nname = \"rabbitmq\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:rabbitmq\"\n\n[[transforms.processing.logs.pipelines.rabbitmq.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"=%{_status} REPORT(====)? (%{_date_d}|%{_date_dd}) =(==)?\\\\s*%{data:message}\",\"%{_date_latest}\\\\s\\\\[%{_status}\\\\]\\\\s*%{data:message}\"],\naliases: {\n\"rabbit_default\": \"=%{_status} REPORT(====)? (%{_date_d}|%{_date_dd}) =(==)?\\\\s*%{data:message}\",\n\"rabbit_latest\": \"%{_date_latest}\\\\s\\\\[%{_status}\\\\]\\\\s*%{data:message}\",\n\"_date_d\": \"%{date(\\\"d-MMM-yyyy::HH:mm:ss\\\"):timestamp}\",\n\"_date_dd\": \"%{date(\\\"dd-MMM-yyyy::HH:mm:ss\\\"):timestamp}\",\n\"_date_latest\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss.SSS\\\"):timestamp}\",\n\"_status\": \"%{word:status}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.rabbitmq.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.rabbitmq.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.status) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.rabbitmq.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.message) {\n.message = .custom.message\n}\n'''\n\n[transforms.processing.logs.pipelines.zookeeper]\nname = \"zookeeper\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:zookeeper\"\n\n[[transforms.processing.logs.pipelines.zookeeper.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"(%{_date_ms}|%{_duration})\\\\s+\\\\[%{_thread_name}\\\\]\\\\s+%{_status}\\\\s+%{_logger_name}\\\\s*(%{_context}\\\\s*)?- %{data:msg}((\\\\n|\\\\t)%{data:error.stack})?\",\"%{_date} %{_status}\\\\s+%{_logger_name}:%{_line}\\\\s+- %{data:msg}((\\\\n|\\\\t)%{data:error.stack})?\"],\naliases: {\n\"Zookeeper_default\": \"(%{_date_ms}|%{_duration})\\\\s+\\\\[%{_thread_name}\\\\]\\\\s+%{_status}\\\\s+%{_logger_name}\\\\s*(%{_context}\\\\s*)?- %{data:msg}((\\\\n|\\\\t)%{data:error.stack})?\",\n\"Zookeeper_recommended\": \"%{_date} %{_status}\\\\s+%{_logger_name}:%{_line}\\\\s+- %{data:msg}((\\\\n|\\\\t)%{data:error.stack})?\",\n\"_date\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss\\\"):timestamp}\",\n\"_date_ms\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss,SSS\\\"):timestamp}\",\n\"_duration\": \"%{integer:duration}\",\n\"_thread_name\": \"%{notSpace:logger.thread_name}\",\n\"_status\": \"%{word:status}\",\n\"_logger_name\": \"%{notSpace:logger.name}\",\n\"_context\": \"%{notSpace:logger.context}\",\n\"_line\": \"%{integer:line}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.zookeeper.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .error.stack,\npatterns: [\"%{notSpace:error.kind}: %{data:error.message}(\\\\n|\\\\t).*\"],\naliases: {\n\"error_rule\": \"%{notSpace:error.kind}: %{data:error.message}(\\\\n|\\\\t).*\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.zookeeper.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.zookeeper.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.status) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.zookeeper.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.msg) {\n.message = .custom.msg\n}\n'''\n\n[transforms.processing.logs.pipelines.elasticsearch]\nname = \"elasticsearch\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:elasticsearch\"\n\n[[transforms.processing.logs.pipelines.elasticsearch.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"\\\\[(?\u003e%{_date}|%{_date_format2})\\\\]\\\\[%{_status}\\\\s*\\\\]\\\\[index.search.slowlog.%{_operation}\\\\] (\\\\[%{_node}\\\\] )?\\\\[%{_index}\\\\]\\\\[%{_shard}\\\\] took\\\\[.*\\\\], took_millis\\\\[%{_duration}\\\\].*\",\"\\\\[(?\u003e%{_date}|%{_date_format2})\\\\]\\\\[%{_status}\\\\s*\\\\]\\\\[index.indexing.slowlog.%{_operation}\\\\] (\\\\[%{_node}\\\\] )?\\\\[%{_index}\\\\] took\\\\[.*\\\\], took_millis\\\\[%{_duration}\\\\].*\",\"\\\\[(?\u003e%{_date}|%{_date_format2})\\\\]\\\\[%{_status}\\\\s*\\\\]\\\\[%{_logger}\\\\s*\\\\]\\\\s*(\\\\[%{_node}\\\\])?.*\"],\naliases: {\n\"Elasticsearch_search_query\": \"\\\\[(?\u003e%{_date}|%{_date_format2})\\\\]\\\\[%{_status}\\\\s*\\\\]\\\\[index.search.slowlog.%{_operation}\\\\] (\\\\[%{_node}\\\\] )?\\\\[%{_index}\\\\]\\\\[%{_shard}\\\\] took\\\\[.*\\\\], took_millis\\\\[%{_duration}\\\\].*\",\n\"Elasticsearch_slow_indexing\": \"\\\\[(?\u003e%{_date}|%{_date_format2})\\\\]\\\\[%{_status}\\\\s*\\\\]\\\\[index.indexing.slowlog.%{_operation}\\\\] (\\\\[%{_node}\\\\] )?\\\\[%{_index}\\\\] took\\\\[.*\\\\], took_millis\\\\[%{_duration}\\\\].*\",\n\"Elasticsearch_default\": \"\\\\[(?\u003e%{_date}|%{_date_format2})\\\\]\\\\[%{_status}\\\\s*\\\\]\\\\[%{_logger}\\\\s*\\\\]\\\\s*(\\\\[%{_node}\\\\])?.*\",\n\"_date\": \"%{date(\\\"yyyy-MM-dd'T'HH:mm:ss,SSS\\\"):timestamp}\",\n\"_date_format2\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss,SSS\\\"):timestamp}\",\n\"_status\": \"%{word:level}\",\n\"_operation\": \"%{notSpace:elasticsearch.operation}\",\n\"_node\": \"%{hostname:nodeId}\",\n\"_index\": \"%{notSpace:elasticsearch.index}\",\n\"_shard\": \"%{integer:elasticsearch.shard}\",\n\"_duration\": \"%{integer:duration:scale(1000000)}\",\n\"_logger\": \"%{notSpace:logger.name}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.elasticsearch.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.elasticsearch.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.elasticsearch.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.nodeId) {\n.custom.node_name = .custom.nodeId\n}\n'''\n\n[transforms.processing.logs.pipelines.kafka]\nname = \"kafka\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:kafka\"\n\n[[transforms.processing.logs.pipelines.kafka.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"(%{_date_ms}|%{_duration})\\\\s+\\\\[%{_thread_name}\\\\]\\\\s+%{_status}\\\\s+%{_logger_name}\\\\s*(%{_context}\\\\s*)?- %{data:msg}((\\\\n|\\\\t)%{data:error.stack})?\",\"%{_date} %{_status}\\\\s+%{_logger_name}:%{_line}\\\\s+- %{data:msg}((\\\\n|\\\\t)%{data:error.stack})?\",\"\\\\[%{_date_ms}\\\\] %{_status} %{data:msg} \\\\(%{_logger_name}\\\\)\"],\naliases: {\n\"Kafka_default\": \"(%{_date_ms}|%{_duration})\\\\s+\\\\[%{_thread_name}\\\\]\\\\s+%{_status}\\\\s+%{_logger_name}\\\\s*(%{_context}\\\\s*)?- %{data:msg}((\\\\n|\\\\t)%{data:error.stack})?\",\n\"Kafka_recommended\": \"%{_date} %{_status}\\\\s+%{_logger_name}:%{_line}\\\\s+- %{data:msg}((\\\\n|\\\\t)%{data:error.stack})?\",\n\"Kafka_standard\": \"\\\\[%{_date_ms}\\\\] %{_status} %{data:msg} \\\\(%{_logger_name}\\\\)\",\n\"_date\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss\\\"):timestamp}\",\n\"_date_ms\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss,SSS\\\"):timestamp}\",\n\"_duration\": \"%{integer:duration}\",\n\"_thread_name\": \"%{notSpace:logger.thread_name}\",\n\"_status\": \"%{word:status}\",\n\"_logger_name\": \"%{notSpace:logger.name}\",\n\"_context\": \"%{notSpace:logger.context}\",\n\"_line\": \"%{integer:line}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.kafka.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .error.stack,\npatterns: [\"%{notSpace:error.kind}: %{data:error.message}(\\\\n|\\\\t).*\"],\naliases: {\n\"error_rule\": \"%{notSpace:error.kind}: %{data:error.message}(\\\\n|\\\\t).*\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.kafka.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.kafka.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.status) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.kafka.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.msg) {\n.message = .custom.msg\n}\n'''\n\n[transforms.processing.logs.pipelines.couchdb]\nname = \"couchdb\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:couchdb\"\n\n[[transforms.processing.logs.pipelines.couchdb.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"\\\\[%{_date_access}\\\\] \\\\[%{_level}\\\\] %{notSpace} %{_client_ip} - - %{_method} %{_url} %{_status_code}.*\",\"\\\\[%{_level}\\\\] %{_date} %{_user}@%{_client_ip} %{notSpace} (-------- CRASH REPORT\\\\s*%{data:error.stack}|%{data})\",\"%{date(\\\"yyyy-MM-dd HH:mm:ss.SSS\\\"):date_access} \\\\[%{_level}\\\\] .*\"],\naliases: {\n\"http_rule\": \"\\\\[%{_date_access}\\\\] \\\\[%{_level}\\\\] %{notSpace} %{_client_ip} - - %{_method} %{_url} %{_status_code}.*\",\n\"default_format\": \"\\\\[%{_level}\\\\] %{_date} %{_user}@%{_client_ip} %{notSpace} (-------- CRASH REPORT\\\\s*%{data:error.stack}|%{data})\",\n\"fallback_format\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss.SSS\\\"):date_access} \\\\[%{_level}\\\\] .*\",\n\"_date_access\": \"(%{date(\\\"EEE, dd MMM yyyy HH:mm:ss z\\\"):date_access}|%{date(\\\"EEE, d MMM yyyy HH:mm:ss z\\\"):date_access})\",\n\"_date\": \"%{date(\\\"yyyy-MM-dd'T'HH:mm:ss.SSSSSSZ\\\"):date_access}\",\n\"_level\": \"%{word:level}\",\n\"_method\": \"%{word:http.method}\",\n\"_url\": \"%{notSpace:http.url}\",\n\"_status_code\": \"%{number:http.status_code}\",\n\"_client_ip\": \"%{notSpace:network.client.ip}\",\n\"_user\": \"%{notSpace:db.user}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.couchdb.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.date_access) {\n.timestamp = .custom.date_access\n}\n'''\n\n[[transforms.processing.logs.pipelines.couchdb.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.couchdb.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_url(.custom.http.url); err == null) {\n  .custom.http.url_details = details\n}\n'''\n\n[transforms.processing.logs.pipelines.docker]\nname = \"docker\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:docker\"\n\n[[transforms.processing.logs.pipelines.docker.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_level}%{_kube_date}\\\\s+%{_thread_id} %{_logger_name}:%{_line}\\\\].*\",\"%{_client_ip} %{_ident} %{_auth} \\\\[%{_date_access}\\\\] \\\"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\\\" %{_status_code} (?\u003e%{_bytes_written}|-) \\\"%{_referer}\\\" \\\"%{_user_agent}\\\"( \\\"%{_x_forwarded_for}\\\")?.*\",\"(?\u003e\\\\[ %{word:process.name} \\\\] )?%{_dd_date} \\\\| %{word:level} \\\\| \\\\(%{_logger_name}:%{_line} in %{word:datadog.process}\\\\) \\\\| .*\"],\naliases: {\n\"Kubernetes_format\": \"%{_level}%{_kube_date}\\\\s+%{_thread_id} %{_logger_name}:%{_line}\\\\].*\",\n\"access.combined\": \"%{_client_ip} %{_ident} %{_auth} \\\\[%{_date_access}\\\\] \\\"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\\\" %{_status_code} (?\u003e%{_bytes_written}|-) \\\"%{_referer}\\\" \\\"%{_user_agent}\\\"( \\\"%{_x_forwarded_for}\\\")?.*\",\n\"datadog_format\": \"(?\u003e\\\\[ %{word:process.name} \\\\] )?%{_dd_date} \\\\| %{word:level} \\\\| \\\\(%{_logger_name}:%{_line} in %{word:datadog.process}\\\\) \\\\| .*\",\n\"_auth\": \"%{notSpace:http.auth:nullIf(\\\"-\\\")}\",\n\"_bytes_written\": \"%{integer:network.bytes_written}\",\n\"_client_ip\": \"%{ipOrHost:network.client.ip}\",\n\"_version\": \"HTTP\\\\/%{regex(\\\"\\\\\\\\d+\\\\\\\\.\\\\\\\\d+\\\"):http.version}\",\n\"_url\": \"%{notSpace:http.url}\",\n\"_ident\": \"%{notSpace:http.ident:nullIf(\\\"-\\\")}\",\n\"_user_agent\": \"%{regex(\\\"[^\\\\\\\\\\\\\\\"]*\\\"):http.useragent}\",\n\"_referer\": \"%{notSpace:http.referer}\",\n\"_status_code\": \"%{integer:http.status_code}\",\n\"_method\": \"%{word:http.method}\",\n\"_date_access\": \"%{date(\\\"dd/MMM/yyyy:HH:mm:ss Z\\\"):timestamp}\",\n\"_dd_date\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss z\\\"):timestamp}\",\n\"_x_forwarded_for\": \"%{regex(\\\"[^\\\\\\\\\\\\\\\"]*\\\"):http._x_forwarded_for:nullIf(\\\"-\\\")}\",\n\"_level\": \"%{regex(\\\"[\\\\\\\\w]\\\"):level}\",\n\"_kube_date\": \"%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):timestamp}\",\n\"_thread_id\": \"%{number:logger.thread_id}\",\n\"_logger_name\": \"%{notSpace:logger.name}\",\n\"_line\": \"%{number:lineno}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.docker.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.docker.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[transforms.processing.logs.pipelines.datadog_agent]\nname = \"datadog_agent\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:(agent OR datadog-agent OR datadog-agent-cluster-worker OR datadog-cluster-agent OR process-agent OR security-agent OR system-probe OR trace-agent)\"\n\n[[transforms.processing.logs.pipelines.datadog_agent.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"        %{date(\\\"yyyy-MM-dd HH:mm:ss z\\\"):timestamp} \\\\| %{notSpace:agent} \\\\| %{word:level} \\\\| \\\\(%{notSpace:filename}:%{number:lineno} in %{word:process}\\\\) \\\\|( %{data} \\\\|)?( - \\\\|)?( \\\\(%{notSpace:pyFilename}:%{number:pyLineno}\\\\) \\\\|)?%{data}\",\"%{date(\\\"yyyy-MM-dd HH:mm:ss z\\\"):timestamp} \\\\| %{word:level} \\\\| \\\\(%{notSpace:filename}:%{number:lineno} in %{word:process}\\\\)%{data}\",\"     %{date(\\\"yyyy-MM-dd HH:mm:ss z\\\"):timestamp} \\\\| %{notSpace:agent} \\\\| %{word:level}\\\\s+\\\\| %{word:class} \\\\| %{data}\"],\naliases: {\n\"agent_rule\": \"        %{date(\\\"yyyy-MM-dd HH:mm:ss z\\\"):timestamp} \\\\| %{notSpace:agent} \\\\| %{word:level} \\\\| \\\\(%{notSpace:filename}:%{number:lineno} in %{word:process}\\\\) \\\\|( %{data} \\\\|)?( - \\\\|)?( \\\\(%{notSpace:pyFilename}:%{number:pyLineno}\\\\) \\\\|)?%{data}\",\n\"agent_rule_pre_611\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss z\\\"):timestamp} \\\\| %{word:level} \\\\| \\\\(%{notSpace:filename}:%{number:lineno} in %{word:process}\\\\)%{data}\",\n\"jmxfetch_rule\": \"     %{date(\\\"yyyy-MM-dd HH:mm:ss z\\\"):timestamp} \\\\| %{notSpace:agent} \\\\| %{word:level}\\\\s+\\\\| %{word:class} \\\\| %{data}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.datadog_agent.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.datadog_agent.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[transforms.processing.logs.pipelines.ruby]\nname = \"ruby\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:ruby\"\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.logger) {\n.custom.logger.name = .custom.logger\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.thread) {\n.custom.logger.thread_name = .custom.thread\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.exception) {\n.custom.error.stack = .custom.exception\n} else if exists(.custom.stack_trace) {\n.custom.error.stack = .custom.stack_trace\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"(?\u003e%{_ruby_log_prefix}\\\\s+|%{_trace_rule}\\\\s+)?%{_activate_status} %{integer:http.status_code}(?: (?:%{word}|Internal Server Error))? in %{number:duration}ms \\\\((?\u003eViews: %{number:views}ms \\\\| )?ActiveRecord: %{number:activerecord}ms\\\\)\",\"(?\u003e%{_ruby_log_prefix}\\\\s+|%{_trace_rule}\\\\s+)?%{_activate_status} by %{notSpace:processor}.*\",\"(?\u003e%{_ruby_log_prefix}\\\\s+|%{_trace_rule}\\\\s+)?%{_activate_status} %{word:http.method} \\\"%{notSpace:http.url_details.path}\\\" for %{ipOrHost:network.client.ip}.*\",\"%{_datadog_prefix} %{data}(?\u003e(\\\\n|\\\\t)%{data:error.stack})?\",\"(?\u003e%{_ruby_log_prefix}\\\\s+|%{_trace_rule}\\\\s+)?Received: %{data::json}\",\"%{_ruby_log_prefix}\\\\s+%{data:error.message}(?\u003e(\\\\n|\\\\t)%{data:error.stack})?\",\"%{data}\"],\naliases: {\n\"completed_rule\": \"(?\u003e%{_ruby_log_prefix}\\\\s+|%{_trace_rule}\\\\s+)?%{_activate_status} %{integer:http.status_code}(?: (?:%{word}|Internal Server Error))? in %{number:duration}ms \\\\((?\u003eViews: %{number:views}ms \\\\| )?ActiveRecord: %{number:activerecord}ms\\\\)\",\n\"processing_rule\": \"(?\u003e%{_ruby_log_prefix}\\\\s+|%{_trace_rule}\\\\s+)?%{_activate_status} by %{notSpace:processor}.*\",\n\"started_rule\": \"(?\u003e%{_ruby_log_prefix}\\\\s+|%{_trace_rule}\\\\s+)?%{_activate_status} %{word:http.method} \\\"%{notSpace:http.url_details.path}\\\" for %{ipOrHost:network.client.ip}.*\",\n\"datadog_format\": \"%{_datadog_prefix} %{data}(?\u003e(\\\\n|\\\\t)%{data:error.stack})?\",\n\"received_rule\": \"(?\u003e%{_ruby_log_prefix}\\\\s+|%{_trace_rule}\\\\s+)?Received: %{data::json}\",\n\"Ruby_default\": \"%{_ruby_log_prefix}\\\\s+%{data:error.message}(?\u003e(\\\\n|\\\\t)%{data:error.stack})?\",\n\"Ruby_keyvalue\": \"%{data}\",\n\"_date\": \"(?:%{date(\\\"yyyy-MM-dd'T'HH:mm:ss.SSSSSS\\\"):date}|%{date(\\\"yyyy-MM-dd'T'HH:mm:ss.SSS\\\"):date})\",\n\"_status\": \"%{word:level}\",\n\"_thread_id\": \"%{word:logger.thread_id}\",\n\"_thread_name\": \"%{notSpace:logger.thread_name}\",\n\"_logger_name\": \"%{notSpace:logger.name}\",\n\"_ruby_log_prefix\": \"%{word}, \\\\[%{_date} #%{_thread_id}\\\\]\\\\s+%{_status}\\\\s+--\\\\s+(?:%{_logger_name})?:(?:\\\\s+%{_trace_rule})?\",\n\"_trace_rule\": \"\\\\[%{data}dd.trace_id=%{word:dd.trace_id} dd.span_id=%{word:dd.span_id}\\\\]\",\n\"_datadog_prefix\": \"\\\\[%{date(\\\"yyyy-MM-dd HH:mm:ss Z\\\"):date}\\\\]\\\\[%{word:application}\\\\]\\\\[%{_status}\\\\]%{_trace_rule}\",\n\"_activate_status\": \"%{word:active_directory.process_status}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.date) {\n.timestamp = .custom.date\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .error.stack,\npatterns: [\"%{notSpace:error.kind}: %{data:error.message}(\\\\n|\\\\t).*\"],\naliases: {\n\"error_rule\": \"%{notSpace:error.kind}: %{data:error.message}(\\\\n|\\\\t).*\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.method) {\n.custom.http.method = .custom.method\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.path) {\n.custom.http.url_details.path = .custom.path\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.status) {\n.custom.http.status_code = .custom.status\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.trace_id) {\n.trace_id = .custom.dd.trace_id\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.env) {\n.custom.env = .custom.dd.env\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.version) {\n.custom.version = .custom.dd.version\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.service) {\n.service = .custom.dd.service\n}\n'''\n\n[[transforms.processing.logs.pipelines.ruby.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.duration*1000000; err == null) {\n  .custom.duration = result\n}\n'''\n\n[transforms.processing.logs.pipelines.vault]\nname = \"vault\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:vault\"\n\n[[transforms.processing.logs.pipelines.vault.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_date}\\\\s+\\\\[%{_level}\\\\]\\\\s+%{notSpace:vault.service}:\\\\s+%{data:message}\",\"%{_date}\\\\s+\\\\[%{_level}\\\\]\\\\s+%{data:message}\"],\naliases: {\n\"vault_server_svc\": \"%{_date}\\\\s+\\\\[%{_level}\\\\]\\\\s+%{notSpace:vault.service}:\\\\s+%{data:message}\",\n\"vault_server\": \"%{_date}\\\\s+\\\\[%{_level}\\\\]\\\\s+%{data:message}\",\n\"_date\": \"%{date(\\\"yyyy-MM-dd'T'HH:mm:ss.SSSZ\\\"):timestamp}\",\n\"_level\": \"%{word:level}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.vault.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.vault.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.vault.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.message) {\n.message = .custom.message\n}\n'''\n\n[[transforms.processing.logs.pipelines.vault.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.auth.display_name) {\n.custom.usr.id = .custom.auth.display_name\n} else if exists(.custom.auth.metatdata.username) {\n.custom.usr.id = .custom.auth.metatdata.username\n}\n'''\n\n[[transforms.processing.logs.pipelines.vault.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.request.path) {\n.custom.http.url_details.path = .custom.request.path\n}\n'''\n\n[[transforms.processing.logs.pipelines.vault.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.request.data.http_status_code) {\n.custom.http.status_code = .custom.request.data.http_status_code\n}\n'''\n\n[[transforms.processing.logs.pipelines.vault.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.request.remote_address) {\n.custom.network.client.ip = .custom.request.remote_address\n}\n'''\n\n[[transforms.processing.logs.pipelines.vault.transforms]]\ntype = \"remap\"\nsource = '''\n\n#TODO: geo-ip-parser\n'''\n\n[[transforms.processing.logs.pipelines.vault.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.request.operation) {\n.custom.http.method = .custom.request.operation\n}\n'''\n\n[transforms.processing.logs.pipelines.nginx_ingress_controller]\nname = \"nginx_ingress_controller\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:nginx-ingress-controller\"\n\n[[transforms.processing.logs.pipelines.nginx_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_client_ip}(?: - \\\\[%{notSpace}\\\\])? - %{_ident} \\\\[%{_date_access}\\\\] \\\"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\\\" %{_status_code} (?\u003e%{_bytes_written}|-) \\\"%{_referer}\\\" \\\"%{_user_agent}\\\" %{_request_size} %{_duration} \\\\[%{_proxy_name}\\\\](?: \\\\[%{_alternate_proxy_name}?\\\\])? (?:%{_upstream_ip}:%{_upstream_port}|-)(?:, %{notSpace})?(?:, %{notSpace})? (?:%{_bytes_read}|-)(?:, %{number}|, -)?(?:, %{number}|, -)? (?:%{_upstream_time}|-)(?:, %{number}|, -)?(?:, %{number}|, -)? (?:%{_upstream_status}|-)(?:, %{number}|, -)?(?:, %{number}|, -)?(?: %{_request_id})?.*\",\"%{date(\\\"yyyy/MM/dd HH:mm:ss\\\"):date_access} \\\\[%{word:level}\\\\] %{data:error.message}(, %{data})?\",\"%{regex(\\\"\\\\\\\\w\\\"):level}%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):date_access}\\\\s+%{number} %{notSpace:logger.name}:%{number:lineno}\\\\] .*\"],\naliases: {\n\"access.common\": \"%{_client_ip}(?: - \\\\[%{notSpace}\\\\])? - %{_ident} \\\\[%{_date_access}\\\\] \\\"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\\\" %{_status_code} (?\u003e%{_bytes_written}|-) \\\"%{_referer}\\\" \\\"%{_user_agent}\\\" %{_request_size} %{_duration} \\\\[%{_proxy_name}\\\\](?: \\\\[%{_alternate_proxy_name}?\\\\])? (?:%{_upstream_ip}:%{_upstream_port}|-)(?:, %{notSpace})?(?:, %{notSpace})? (?:%{_bytes_read}|-)(?:, %{number}|, -)?(?:, %{number}|, -)? (?:%{_upstream_time}|-)(?:, %{number}|, -)?(?:, %{number}|, -)? (?:%{_upstream_status}|-)(?:, %{number}|, -)?(?:, %{number}|, -)?(?: %{_request_id})?.*\",\n\"error.format\": \"%{date(\\\"yyyy/MM/dd HH:mm:ss\\\"):date_access} \\\\[%{word:level}\\\\] %{data:error.message}(, %{data})?\",\n\"controller_format\": \"%{regex(\\\"\\\\\\\\w\\\"):level}%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):date_access}\\\\s+%{number} %{notSpace:logger.name}:%{number:lineno}\\\\] .*\",\n\"_request_id\": \"%{notSpace:http.request_id}\",\n\"_upstream_status\": \"%{number:http.upstream_status_code}\",\n\"_upstream_time\": \"%{number:http.upstream_duration}\",\n\"_bytes_read\": \"%{number:network.bytes_read}\",\n\"_upstream_port\": \"%{number:network.destination.port}\",\n\"_upstream_ip\": \"%{ipOrHost:network.destination.ip}\",\n\"_proxy_name\": \"%{notSpace:proxy.name}\",\n\"_alternate_proxy_name\": \"%{notSpace:proxy.alternate_name}\",\n\"_duration\": \"%{number:duration:scale(1000000000)}\",\n\"_request_size\": \"%{number:network.request_size}\",\n\"_bytes_written\": \"%{integer:network.bytes_written}\",\n\"_client_ip\": \"%{ipOrHost:network.client.ip}\",\n\"_version\": \"HTTP\\\\/%{regex(\\\"\\\\\\\\d+\\\\\\\\.\\\\\\\\d+\\\"):http.version}\",\n\"_url\": \"%{notSpace:http.url}\",\n\"_ident\": \"%{notSpace:http.ident:nullIf(\\\"-\\\")}\",\n\"_user_agent\": \"%{regex(\\\"[^\\\\\\\\\\\\\\\"]*\\\"):http.useragent}\",\n\"_referer\": \"%{notSpace:http.referer}\",\n\"_status_code\": \"%{integer:http.status_code}\",\n\"_method\": \"%{word:http.method}\",\n\"_date_access\": \"%{date(\\\"dd/MMM/yyyy:HH:mm:ss Z\\\"):date_access}\",\n\"_x_forwarded_for\": \"%{regex(\\\"[^\\\\\\\\\\\\\\\"]*\\\"):http._x_forwarded_for:nullIf(\\\"-\\\")}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.nginx_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.client) {\n.custom.network.client.ip = .custom.client\n}\n'''\n\n[[transforms.processing.logs.pipelines.nginx_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .request,\npatterns: [\"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\"],\naliases: {\n\"request_parsing\": \"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\",\n\"_method\": \"%{word:http.method}\",\n\"_url\": \"%{notSpace:http.url}\",\n\"_version\": \"HTTP\\\\/%{regex(\\\"\\\\\\\\d+\\\\\\\\.\\\\\\\\d+\\\"):http.version}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.nginx_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_url(.custom.http.url); err == null) {\n  .custom.http.url_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.nginx_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_user_agent(.custom.http.useragent); err == null) {\n  .custom.http.useragent_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.nginx_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.date_access) {\n.timestamp = .custom.date_access\n}\n'''\n\n[[transforms.processing.logs.pipelines.nginx_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\nif match_datadog_query(., \"@http.status_code:[200 TO 299]\") {\n.custom.http.status_category = \"OK\"\n} else if match_datadog_query(., \"@http.status_code:[300 TO 399]\") {\n.custom.http.status_category = \"notice\"\n} else if match_datadog_query(., \"@http.status_code:[400 TO 499]\") {\n.custom.http.status_category = \"warning\"\n} else if match_datadog_query(., \"@http.status_code:[500 TO 599]\") {\n.custom.http.status_category = \"error\"\n}\n'''\n\n[[transforms.processing.logs.pipelines.nginx_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.http.status_category) ?? string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[transforms.processing.logs.pipelines.mysql]\nname = \"mysql\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:mysql\"\n\n[[transforms.processing.logs.pipelines.mysql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"(%{_timestamp}\\\\s+|(?:%{_rawtimestamp}\\\\s+)?)%{integer:thread_id}\\\\s+%{_operation}\\\\s+%{_raw_query}\",\"(%{_timestamp}|%{_timestamp_mariadb_post_1015}) %{integer:thread_id} \\\\[%{_severity}\\\\] %{data:message}\",\"%{_rawtimestamp}\\\\s+(?\u003eInnoDB:|\\\\[%{_severity}\\\\])\\\\s+%{data:message}\",\"(%{_time_line}\\\\s)?(%{_user_line}\\\\s)?\\\\# %{data}(%{_instance_line}\\\\s)?%{_set_line}\\\\s%{_query_line}\"],\naliases: {\n\"query_format\": \"(%{_timestamp}\\\\s+|(?:%{_rawtimestamp}\\\\s+)?)%{integer:thread_id}\\\\s+%{_operation}\\\\s+%{_raw_query}\",\n\"default_format\": \"(%{_timestamp}|%{_timestamp_mariadb_post_1015}) %{integer:thread_id} \\\\[%{_severity}\\\\] %{data:message}\",\n\"raw_default_format\": \"%{_rawtimestamp}\\\\s+(?\u003eInnoDB:|\\\\[%{_severity}\\\\])\\\\s+%{data:message}\",\n\"slow_query_format\": \"(%{_time_line}\\\\s)?(%{_user_line}\\\\s)?\\\\# %{data}(%{_instance_line}\\\\s)?%{_set_line}\\\\s%{_query_line}\",\n\"_timestamp\": \"%{date(\\\"yyyy-MM-dd'T'HH:mm:ss.SSSSSSZ\\\"):db.date}\",\n\"_timestamp_mariadb_post_1015\": \"(%{date(\\\"yyyy-MM-dd HH:mm:ss\\\"):db.date}|%{date(\\\"yyyy-MM-dd  H:mm:ss\\\"):db.date})\",\n\"_rawtimestamp\": \"%{date(\\\"yyMMdd HH:mm:ss\\\"):db.date}\",\n\"_severity\": \"%{notSpace:db.severity}\",\n\"_client_ip\": \"%{ipOrHost:network.client.ip}\",\n\"_client_port\": \"%{integer:network.client.port}\",\n\"_operation\": \"%{word:db.operation}\",\n\"_database\": \"%{word:db.instance}\",\n\"_raw_query\": \"%{data:db.statement}\",\n\"_time_line\": \"\\\\# Time: %{notSpace}(\\\\s+%{notSpace})?\",\n\"_user_line\": \"\\\\# User@Host\\\\: %{notSpace:db.user}\\\\s+@\\\\s+%{notSpace:db.host}\\\\s+\\\\[(%{notSpace:network.client.ip})?\\\\](\\\\s+Id\\\\:\\\\s+%{number:mysql.query.id})?\",\n\"_instance_line\": \"use %{notSpace:db.instance};\",\n\"_set_line\": \"SET timestamp=%{number:mysql.query.timestamp};\",\n\"_query_line\": \"%{data:db.slow_statement}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.mysql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .db.slow_statement,\npatterns: [\"%{word:db.operation} .*\"],\naliases: {\n\"slow_query_format\": \"%{word:db.operation} .*\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.mysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.db.slow_statement) {\n.custom.db.statement = .custom.db.slow_statement\n}\n'''\n\n[[transforms.processing.logs.pipelines.mysql.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.Query_time * 1000000000; err == null) {\n  .custom.duration = result\n}\n'''\n\n[[transforms.processing.logs.pipelines.mysql.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.mysql.query.timestamp * 1000; err == null) {\n  .custom.db.date = result\n}\n'''\n\n[[transforms.processing.logs.pipelines.mysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.Bytes_sent) {\n.custom.network.bytes_written = .custom.Bytes_sent\n}\n'''\n\n[[transforms.processing.logs.pipelines.mysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.Bytes_received) {\n.custom.network.bytes_read = .custom.Bytes_received\n}\n'''\n\n[[transforms.processing.logs.pipelines.mysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.db.date) {\n.timestamp = .custom.db.date\n}\n'''\n\n[[transforms.processing.logs.pipelines.mysql.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.db.severity) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[transforms.processing.logs.pipelines.kubernetes_cluster_autoscaler]\nname = \"kubernetes_cluster_autoscaler\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:cluster-autoscaler\"\n\n[[transforms.processing.logs.pipelines.kubernetes_cluster_autoscaler.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{regex(\\\"\\\\\\\\w\\\"):level}%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):timestamp}\\\\s+%{number:logger.thread_id} %{notSpace:logger.name}:%{number:lineno}\\\\] %{data:msg}\"],\naliases: {\n\"cluster_scheduler\": \"%{regex(\\\"\\\\\\\\w\\\"):level}%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):timestamp}\\\\s+%{number:logger.thread_id} %{notSpace:logger.name}:%{number:lineno}\\\\] %{data:msg}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.kubernetes_cluster_autoscaler.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.kubernetes_cluster_autoscaler.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.kubernetes_cluster_autoscaler.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.msg) {\n.message = .custom.msg\n}\n'''\n\n[transforms.processing.logs.pipelines.aws_alb_ingress_controller]\nname = \"aws_alb_ingress_controller\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:aws-alb-ingress-controller\"\n\n[[transforms.processing.logs.pipelines.aws_alb_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{regex(\\\"\\\\\\\\w\\\"):level}%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):timestamp}\\\\s+%{number:logger.thread_id} %{notSpace:logger.name}:%{number:lineno}\\\\] %{data:msg}\"],\naliases: {\n\"aws_alb_ingress_controller\": \"%{regex(\\\"\\\\\\\\w\\\"):level}%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):timestamp}\\\\s+%{number:logger.thread_id} %{notSpace:logger.name}:%{number:lineno}\\\\] %{data:msg}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.aws_alb_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.aws_alb_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.aws_alb_ingress_controller.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.msg) {\n.message = .custom.msg\n}\n'''\n\n[transforms.processing.logs.pipelines.proxysql]\nname = \"proxysql\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:proxysql\"\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_longDate}\\\\s+%{_logger}\\\\:\\\\s+%{_level}\\\\s+%{data:message}\",\"%{_longDate}\\\\s+%{_level}\\\\s+%{data:message}\",\"%{_longDate}.*%{_level}%{data:message}\",\"%{data:proxysql_service}\\\\s+%{_revision}\\\\s+--\\\\s+%{notSpace:logger.name}\\\\s+--\\\\s+%{_textDate}\"],\naliases: {\n\"extendedFormat\": \"%{_longDate}\\\\s+%{_logger}\\\\:\\\\s+%{_level}\\\\s+%{data:message}\",\n\"simplifiedFormat\": \"%{_longDate}\\\\s+%{_level}\\\\s+%{data:message}\",\n\"safeGuard\": \"%{_longDate}.*%{_level}%{data:message}\",\n\"stdout\": \"%{data:proxysql_service}\\\\s+%{_revision}\\\\s+--\\\\s+%{notSpace:logger.name}\\\\s+--\\\\s+%{_textDate}\",\n\"_longDate\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss\\\"):date}\",\n\"_textDate\": \"%{date(\\\"EEE MMM dd HH:mm:ss yyyy\\\"):date}\",\n\"_level\": \"\\\\[%{word:level}\\\\]\",\n\"_logger\": \"%{notSpace:logger.name}\\\\:%{number:logger.line_number}\\\\:%{notSpace:logger.method_name}\\\\(.*\\\\)\",\n\"_revision\": \"rev.\\\\s+%{regex(\\\"\\\\\\\\d+.\\\\\\\\d+.\\\\\\\\d+\\\"):revision}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .duration,\npatterns: [\"%{number:duration:scale(1000000)}ms\",\"%{number:duration:scale(1000000000)}s\",\"%{number:duration:scale(1000)}us\",\"%{number:duration:scale(1)}ns\"],\naliases: {\n\"duration_ms\": \"%{number:duration:scale(1000000)}ms\",\n\"duration_s\": \"%{number:duration:scale(1000000000)}s\",\n\"duration_us\": \"%{number:duration:scale(1000)}us\",\n\"duration_ns\": \"%{number:duration:scale(1)}ns\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .client_addr,\npatterns: [\"%{ipOrHost:network.client.ip}:%{number:network.client.port}\"],\naliases: {\n\"ip_and_port\": \"%{ipOrHost:network.client.ip}:%{number:network.client.port}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .proxy_addr,\npatterns: [\"%{ipOrHost:network.proxysql.ip}:%{number:network.proxysql.port}\"],\naliases: {\n\"ip_and_port\": \"%{ipOrHost:network.proxysql.ip}:%{number:network.proxysql.port}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .extra_info,\npatterns: [\"%{notSpace:logger.name}\\\\:%{number:logger.line_number}\\\\:%{notSpace:logger.method_name}\"],\naliases: {\n\"logger\": \"%{notSpace:logger.name}\\\\:%{number:logger.line_number}\\\\:%{notSpace:logger.method_name}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.schemaname) {\n.custom.db.instance = .custom.schemaname\n}\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.username) {\n.custom.db.user = .custom.username\n}\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.thread_id) {\n.custom.logger.thread_id = .custom.thread_id\n}\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .client,\npatterns: [\"%{ipOrHost:network.client.ip}:%{number:network.client.port}\"],\naliases: {\n\"ip_and_port\": \"%{ipOrHost:network.client.ip}:%{number:network.client.port}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.duration_us * 1000; err == null) {\n  .custom.duration = result\n}\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.query) {\n.custom.db.statement = .custom.query\n}\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.rows_affected) {\n.custom.db.rows_affected = .custom.rows_affected\n}\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.rows_sent) {\n.custom.db.rows_sent = .custom.rows_sent\n}\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .server,\npatterns: [\"%{ipOrHost:network.proxysql.ip}:%{number:network.proxysql.port}\"],\naliases: {\n\"ip_and_port\": \"%{ipOrHost:network.proxysql.ip}:%{number:network.proxysql.port}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.date) {\n.timestamp = .custom.date\n} else if exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n} else if exists(.custom.endtime_timestamp_us) {\n.timestamp = .custom.endtime_timestamp_us\n}\n'''\n\n[[transforms.processing.logs.pipelines.proxysql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.message) {\n.message = .custom.message\n}\n'''\n\n[transforms.processing.logs.pipelines.azure]\nname = \"azure\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:(azure OR azure.alertsmanagement OR azure.analysisservices OR azure.apiconfiguration OR azure.apimanagement OR azure.authorization OR azure.automation OR azure.batchai OR azure.batchazure.cache OR azure.blockchain OR azure.cache OR azure.cdn OR azure.classiccompute OR azure.classicstorage OR azure.cognitiveservices OR azure.containerinstance OR azure.containerregistry OR azure.containerservice OR azure.datafactory OR azure.datalakestore OR azure.dbformariadb OR azure.dbformysql OR azure.dbforpostgresql OR azure.devices OR azure.documentdb OR azure.enterpriseknowledgegraph OR azure.eventgrid OR azure.eventhub OR azure.hdinsight OR azure.insights OR azure.iotcentral OR azure.keyvault OR azure.kusto OR azure.logic OR azure.machinelearningservices OR azure.managedidentity OR azure.operationalinsights OR azure.operationsmanagement OR azure.peering OR azure.relay OR azure.resourcegroup OR azure.resources OR azure.search OR azure.security OR azure.servicebus OR azure.servicefabric OR azure.streamanalytics OR azure.subscription OR azure.synapse)\"\n\n[[transforms.processing.logs.pipelines.azure.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.time) {\n.timestamp = .custom.time\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.category) {\n.custom.evt.category = .custom.category\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.operationName) {\n.custom.evt.name = .custom.operationName\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.resultType) {\n.custom.evt.outcome = .custom.resultType\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.callerIpAddress) {\n.custom.network.client.ip = .custom.callerIpAddress\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.durationMs * 1000000; err == null) {\n  .custom.duration = result\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.identity.authorization.evidence.principalId) {\n.custom.usr.id = .custom.identity.authorization.evidence.principalId\n}\n'''\n\n[transforms.processing.logs.pipelines.azure_web]\nname = \"azure_web\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:azure.web\"\n\n[[transforms.processing.logs.pipelines.azure_web.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.time) {\n.timestamp = .custom.time\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_web.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_web.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.category) {\n.custom.evt.category = .custom.category\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_web.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.operationName) {\n.custom.evt.name = .custom.operationName\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_web.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.resultType) {\n.custom.evt.outcome = .custom.resultType\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_web.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.callerIpAddress) {\n.custom.network.client.ip = .custom.callerIpAddress\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_web.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.durationMs * 1000000; err == null) {\n  .custom.duration = result\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_web.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.identity.authorization.evidence.principalId) {\n.custom.usr.id = .custom.identity.authorization.evidence.principalId\n}\n'''\n\n[transforms.processing.logs.pipelines.azure_storage]\nname = \"azure_storage\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:azure.storage\"\n\n[[transforms.processing.logs.pipelines.azure_storage.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.time) {\n.timestamp = .custom.time\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_storage.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_storage.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.category) {\n.custom.evt.category = .custom.category\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_storage.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.operationName) {\n.custom.evt.name = .custom.operationName\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_storage.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.resultType) {\n.custom.evt.outcome = .custom.resultType\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_storage.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.callerIpAddress) {\n.custom.network.client.ip = .custom.callerIpAddress\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_storage.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.durationMs * 1000000; err == null) {\n  .custom.duration = result\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_storage.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.identity.authorization.evidence.principalId) {\n.custom.usr.id = .custom.identity.authorization.evidence.principalId\n}\n'''\n\n[transforms.processing.logs.pipelines.azure_network]\nname = \"azure_network\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:azure.network\"\n\n[[transforms.processing.logs.pipelines.azure_network.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.time) {\n.timestamp = .custom.time\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_network.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_network.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.properties.eventProperties.title) {\n.message = .custom.properties.eventProperties.title\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_network.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.category) {\n.custom.evt.category = .custom.category\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_network.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.operationName) {\n.custom.evt.name = .custom.operationName\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_network.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.resultType) {\n.custom.evt.outcome = .custom.resultType\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_network.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.callerIpAddress) {\n.custom.network.client.ip = .custom.callerIpAddress\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_network.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.durationMs * 1000000; err == null) {\n  .custom.duration = result\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_network.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.identity.authorization.evidence.principalId) {\n.custom.usr.id = .custom.identity.authorization.evidence.principalId\n}\n'''\n\n[transforms.processing.logs.pipelines.azure_compute]\nname = \"azure_compute\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:azure.compute\"\n\n[[transforms.processing.logs.pipelines.azure_compute.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.time) {\n.timestamp = .custom.time\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_compute.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_compute.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.properties.eventProperties.title) {\n.message = .custom.properties.eventProperties.title\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_compute.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.category) {\n.custom.evt.category = .custom.category\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_compute.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.operationName) {\n.custom.evt.name = .custom.operationName\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_compute.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.resultType) {\n.custom.evt.outcome = .custom.resultType\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_compute.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.callerIpAddress) {\n.custom.network.client.ip = .custom.callerIpAddress\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_compute.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.durationMs * 1000000; err == null) {\n  .custom.duration = result\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_compute.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.identity.authorization.evidence.principalId) {\n.custom.usr.id = .custom.identity.authorization.evidence.principalId\n}\n'''\n\n[transforms.processing.logs.pipelines.etcd]\nname = \"etcd\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:etcd\"\n\n[[transforms.processing.logs.pipelines.etcd.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_date} %{word: level} \\\\| (%{notSpace:package}: )?%{data:message}\"],\naliases: {\n\"etcd\": \"%{_date} %{word: level} \\\\| (%{notSpace:package}: )?%{data:message}\",\n\"_date\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss.SSSSSS\\\"):date}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.etcd.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.date) {\n.timestamp = .custom.date\n}\n'''\n\n[[transforms.processing.logs.pipelines.etcd.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.message) {\n.message = .custom.message\n}\n'''\n\n[[transforms.processing.logs.pipelines.etcd.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[transforms.processing.logs.pipelines.glog_pipeline]\nname = \"glog_pipeline\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:(admission-webhook OR api-server OR cert-manager-acmesolver OR cert-manager-cainjector OR cert-manager-controller OR cert-manager-webhook OR cluster-proportional-autoscaler-amd64 OR hyperkube OR ip-masq-agent OR k8s-prometheus-adapter-amd64 OR kube-apiserver OR kube-controller-manager OR kube-proxy OR kube-state-metrics OR metacontroller OR metrics-server-amd64 OR prometheus-operator OR vpa-admission-controller OR vpa-recommender OR vpa-updater)\"\n\n[[transforms.processing.logs.pipelines.glog_pipeline.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{regex(\\\"[IWEF]\\\"):level}%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):timestamp}\\\\s+%{number:logger.thread_id} %{notSpace:logger.name}:%{number:lineno}\\\\] %{data:msg}\"],\naliases: {\n\"glog_rule\": \"%{regex(\\\"[IWEF]\\\"):level}%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):timestamp}\\\\s+%{number:logger.thread_id} %{notSpace:logger.name}:%{number:lineno}\\\\] %{data:msg}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.glog_pipeline.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.glog_pipeline.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.glog_pipeline.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.msg) {\n.message = .custom.msg\n}\n'''\n\n[transforms.processing.logs.pipelines.auth0]\nname = \"auth0\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:auth0\"\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.data.date) {\n.timestamp = .custom.data.date\n}\n'''\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.data.ip) {\n.custom.network.client.ip = .custom.data.ip\n}\n'''\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\n\n#TODO: geo-ip-parser\n'''\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.data.user_agent) {\n.custom.http.useragent = .custom.data.user_agent\n}\n'''\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_user_agent(.custom.http.useragent); err == null) {\n  .custom.http.useragent_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.data.user_name) {\n.custom.usr.id = .custom.data.user_name\n}\n'''\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.data.user_name) {\n.custom.usr.name = .custom.data.user_name\n}\n'''\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.data.details.request.auth.user.email) {\n.custom.usr.email = .custom.data.details.request.auth.user.email\n}\n'''\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\n\n#TODO: lookup-processor\n'''\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\n\n#TODO: lookup-processor\n'''\n\n[[transforms.processing.logs.pipelines.auth0.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.message) {\n.message = .custom.message\n} else if exists(.custom.data.description) {\n.message = .custom.data.description\n} else if exists(.custom.evt.name) {\n.message = .custom.evt.name\n}\n'''\n\n[transforms.processing.logs.pipelines.kube_scheduler__glog_]\nname = \"kube_scheduler__glog_\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:(kube_scheduler OR kube-scheduler)\"\n\n[[transforms.processing.logs.pipelines.kube_scheduler__glog_.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{regex(\\\"\\\\\\\\w\\\"):level}%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):timestamp}\\\\s+%{number:logger.thread_id} %{notSpace:logger.name}:%{number:lineno}\\\\] %{data:msg}\"],\naliases: {\n\"kube_scheduler\": \"%{regex(\\\"\\\\\\\\w\\\"):level}%{date(\\\"MMdd HH:mm:ss.SSSSSS\\\"):timestamp}\\\\s+%{number:logger.thread_id} %{notSpace:logger.name}:%{number:lineno}\\\\] %{data:msg}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.kube_scheduler__glog_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.timestamp) {\n.timestamp = .custom.timestamp\n}\n'''\n\n[[transforms.processing.logs.pipelines.kube_scheduler__glog_.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.kube_scheduler__glog_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.msg) {\n.message = .custom.msg\n}\n'''\n\n[transforms.processing.logs.pipelines.aws_ecs_agent]\nname = \"aws_ecs_agent\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:amazon-ecs-agent\"\n\n[[transforms.processing.logs.pipelines.aws_ecs_agent.transforms]]\ntype = \"remap\"\nsource = '''\nif match_datadog_query(., \"@http.status_code:[200 TO 299]\") {\n.custom.http.status_category = \"OK\"\n} else if match_datadog_query(., \"@http.status_code:[300 TO 399]\") {\n.custom.http.status_category = \"notice\"\n} else if match_datadog_query(., \"@http.status_code:[400 TO 499]\") {\n.custom.http.status_category = \"warning\"\n} else if match_datadog_query(., \"@http.status_code:[500 TO 599]\") {\n.custom.http.status_category = \"error\"\n}\n'''\n\n[[transforms.processing.logs.pipelines.aws_ecs_agent.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.http.status_category) ?? string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.aws_ecs_agent.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.time) {\n.timestamp = .custom.time\n}\n'''\n\n[[transforms.processing.logs.pipelines.aws_ecs_agent.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.msg) {\n.message = .custom.msg\n}\n'''\n\n[transforms.processing.logs.pipelines.nodejs]\nname = \"nodejs\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:nodejs\"\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.msg) {\n.message = .custom.msg\n}\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"(?\u003e\\\\[%{data}dd.trace_id=%{word:dd.trace_id} dd.span_id=%{word:dd.span_id}\\\\]\\\\s*)?\\\\[%{date(\\\"yyyy-MM-dd'T'HH:mm:ss.SSS\\\"):time}\\\\]\\\\s+\\\\[%{word:level}\\\\] %{data}\",\"%{word:http.method} %{notSpace:http.url} %{number:http.status_code} (-|%{number:network.bytes_written}) - (%{number:duration:scale(1000000)} ms|%{number:duration:scale(1000000000)} s)\",\"%{ipOrHost:network.client.ip} %{notSpace:http.ident:nullIf(\\\"-\\\")} %{notSpace:http.auth:nullIf(\\\"-\\\")} \\\\[%{date(\\\"dd/MMM/yyyy:HH:mm:ss Z\\\"):date_access}\\\\] \\\"(?\u003e%{word:http.method} |)%{notSpace:http.url}(?\u003e HTTP\\\\/%{regex(\\\"\\\\\\\\d+\\\\\\\\.\\\\\\\\d+\\\"):http.version}|)\\\" %{number:http.status_code} (?\u003e%{number:network.bytes_written}|-) \\\"%{notSpace:http.referer}\\\" \\\"%{regex(\\\"[^\\\\\\\\\\\\\\\"]*\\\"):http.useragent}\\\".*\",\"(?\u003e\\\\[%{data}dd.trace_id=%{word:dd.trace_id} dd.span_id=%{word:dd.span_id}\\\\]\\\\s*)?%{data::json}\"],\naliases: {\n\"log4js_format\": \"(?\u003e\\\\[%{data}dd.trace_id=%{word:dd.trace_id} dd.span_id=%{word:dd.span_id}\\\\]\\\\s*)?\\\\[%{date(\\\"yyyy-MM-dd'T'HH:mm:ss.SSS\\\"):time}\\\\]\\\\s+\\\\[%{word:level}\\\\] %{data}\",\n\"web_access_morgan\": \"%{word:http.method} %{notSpace:http.url} %{number:http.status_code} (-|%{number:network.bytes_written}) - (%{number:duration:scale(1000000)} ms|%{number:duration:scale(1000000000)} s)\",\n\"morgan_combined\": \"%{ipOrHost:network.client.ip} %{notSpace:http.ident:nullIf(\\\"-\\\")} %{notSpace:http.auth:nullIf(\\\"-\\\")} \\\\[%{date(\\\"dd/MMM/yyyy:HH:mm:ss Z\\\"):date_access}\\\\] \\\"(?\u003e%{word:http.method} |)%{notSpace:http.url}(?\u003e HTTP\\\\/%{regex(\\\"\\\\\\\\d+\\\\\\\\.\\\\\\\\d+\\\"):http.version}|)\\\" %{number:http.status_code} (?\u003e%{number:network.bytes_written}|-) \\\"%{notSpace:http.referer}\\\" \\\"%{regex(\\\"[^\\\\\\\\\\\\\\\"]*\\\"):http.useragent}\\\".*\",\n\"fallback\": \"(?\u003e\\\\[%{data}dd.trace_id=%{word:dd.trace_id} dd.span_id=%{word:dd.span_id}\\\\]\\\\s*)?%{data::json}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.time) {\n.timestamp = .custom.time\n}\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nif match_datadog_query(., \"@http.status_code:[200 TO 299]\") {\n.custom.http.status_category = \"OK\"\n} else if match_datadog_query(., \"@http.status_code:[300 TO 399]\") {\n.custom.http.status_category = \"notice\"\n} else if match_datadog_query(., \"@http.status_code:[400 TO 499]\") {\n.custom.http.status_category = \"warning\"\n} else if match_datadog_query(., \"@http.status_code:[500 TO 599]\") {\n.custom.http.status_category = \"error\"\n}\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nif match_datadog_query(., \"@level:10\") {\n.custom.bunyan_level = \"trace\"\n} else if match_datadog_query(., \"@level:20\") {\n.custom.bunyan_level = \"debug\"\n} else if match_datadog_query(., \"@level:30\") {\n.custom.bunyan_level = \"info\"\n} else if match_datadog_query(., \"@level:40\") {\n.custom.bunyan_level = \"warning\"\n} else if match_datadog_query(., \"@level:50\") {\n.custom.bunyan_level = \"error\"\n} else if match_datadog_query(., \"@level:60\") {\n.custom.bunyan_level = \"fatal\"\n}\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.http.status_category) ?? string(.custom.bunyan_level) ?? string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.trace_id) {\n.trace_id = .custom.dd.trace_id\n}\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_url(.custom.http.url); err == null) {\n  .custom.http.url_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_user_agent(.custom.http.useragent); err == null) {\n  .custom.http.useragent_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.env) {\n.custom.env = .custom.dd.env\n}\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.version) {\n.custom.version = .custom.dd.version\n}\n'''\n\n[[transforms.processing.logs.pipelines.nodejs.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.service) {\n.service = .custom.dd.service\n}\n'''\n\n[transforms.processing.logs.pipelines.postgresql]\nname = \"postgresql\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:postgresql\"\n\n[[transforms.processing.logs.pipelines.postgresql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_prefix} %{_severity}:\\\\s+duration:\\\\s+%{_duration}\\\\s+ms\\\\s+(%{regex(\\\"statement:\\\")}\\\\s+%{_raw_query}|%{data:msg})\",\"%{_prefix} %{_severity}:\\\\s+(%{regex(\\\"statement:\\\")}\\\\s+%{_raw_query}|%{data:msg})\",\"(%{_timestamp}|%{_timestamp_ms} \\\\[%{_proc_id}])\\\\s+%{_severity}:\\\\s+(%{regex(\\\"statement:\\\")}\\\\s+%{_raw_query}|%{data:msg})\"],\naliases: {\n\"suggested_format_with_duration\": \"%{_prefix} %{_severity}:\\\\s+duration:\\\\s+%{_duration}\\\\s+ms\\\\s+(%{regex(\\\"statement:\\\")}\\\\s+%{_raw_query}|%{data:msg})\",\n\"suggested_format\": \"%{_prefix} %{_severity}:\\\\s+(%{regex(\\\"statement:\\\")}\\\\s+%{_raw_query}|%{data:msg})\",\n\"default_format\": \"(%{_timestamp}|%{_timestamp_ms} \\\\[%{_proc_id}])\\\\s+%{_severity}:\\\\s+(%{regex(\\\"statement:\\\")}\\\\s+%{_raw_query}|%{data:msg})\",\n\"_timestamp\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss z\\\"):db.date}\",\n\"_timestamp_ms\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss.SSS z\\\"):db.date}\",\n\"_database\": \"%{notSpace:db.instance}\",\n\"_raw_query\": \"%{data:db.statement}\",\n\"_duration\": \"%{numberExt:duration}\",\n\"_severity\": \"%{notSpace:db.severity}\",\n\"_user\": \"%{notSpace:db.user}\",\n\"_client_ip\": \"%{notSpace:network.client.ip}\",\n\"_proc_id\": \"%{notSpace:postgres.proc_id}\",\n\"_session_id\": \"%{notSpace:postgres.session_id}\",\n\"_app\": \"%{notSpace:postgres.appname}\",\n\"_prefix\": \"%{_timestamp_ms} \\\\[%{_proc_id}\\\\] %{_database} %{_app} %{_user} %{_client_ip} %{_session_id}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.postgresql.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .db.statement,\npatterns: [\"%{word:db.operation} .*\"],\naliases: {\n\"extract_operation\": \"%{word:db.operation} .*\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.postgresql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.db.date) {\n.timestamp = .custom.db.date\n}\n'''\n\n[[transforms.processing.logs.pipelines.postgresql.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.db.severity) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.postgresql.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.db.instance) {\n.custom.db = .custom.db.instance\n}\n'''\n\n[[transforms.processing.logs.pipelines.postgresql.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.duration * 1000000; err == null) {\n  .custom.duration = result\n}\n'''\n\n[transforms.processing.logs.pipelines.cassandra]\nname = \"cassandra\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:cassandra\"\n\n[[transforms.processing.logs.pipelines.cassandra.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_prefix} %{regex(\\\"Compacting\\\"):db.operation}.* %{_keyspace}\\\\/%{_table}:%{data:partition_key} \\\\(%{_bytes} bytes\\\\)\",\"%{_prefix} %{regex(\\\"Flushing\\\"):db.operation}.*\\\\(Keyspace='%{_keyspace}', ColumnFamily='%{_table}'\\\\) %{data}: %{_onheap_total}\\\\/%{_offheap_total}, live: %{_onheap_live}\\\\/%{_offheap_live}, flushing: %{_onheap_flush}\\\\/%{_offheap_flush}, this: %{_onheap_this}\\\\/%{_offheap_this}\",\"%{_prefix} %{regex(\\\"Enqueuing\\\"):db.operation}.* of %{_keyspace}: %{_onheap_bytes}%{data} \\\\(%{_onheap_pct}%\\\\) on-heap, %{_offheap_bytes} \\\\(%{_offheap_pct}%\\\\).*\",\"%{_prefix} %{regex(\\\"Writing\\\"):db.operation}.*-%{_keyspace}%{data}\\\\(%{number:cassandra.bytes:scale(1000000)}%{data}, %{integer:cassandra.ops} ops, %{_onheap_pct}%\\\\/%{_offheap_pct}.*\",\"%{_prefix} Completed %{regex(\\\"flushing\\\"):db.operation} %{_sstable} \\\\(%{number:cassandra.bytes_kb}KiB\\\\) for commitlog %{data:commitlog}\",\"%{_prefix}\\\\s+%{regex(\\\"Compacted\\\"):db.operation}.* to \\\\[%{_sstable}\\\\].\\\\s+%{notSpace:cassandra.bytes_in} bytes to %{notSpace:cassandra.bytes_out} \\\\(\\\\~%{integer:cassandra.percent_of_orig}% of original\\\\) in %{notSpace:cassandra.duration_ms}ms = %{number:cassandra.speed_mb}MB/s.\\\\s+%{notSpace:cassandra.pkeys_in} total partitions merged to %{notSpace:cassandra.pkeys_out}\\\\.\\\\s+Partition merge counts were %{data:cassandra.merge_cnt}\",\"%{_prefix} G.* %{integer:duration:scale(1000000)}ms. %{data}: %{integer:cassandra.eden.orig_bytes} -\u003e %{integer:cassandra.eden.new_bytes}; %{data}: %{integer:cassandra.oldgen.orig_bytes} -\u003e %{integer:cassandra.oldgen.new_bytes};.*\",\"%{_prefix} %{word:cassandra.pool}\\\\s*(?\u003e%{integer:cassandra.cache_used}\\\\s*%{integer:cassandra.cache_size}\\\\s*all|%{integer:cassandra.threads.active}\\\\s*%{integer:cassandra.threads.pending}\\\\s*%{integer:cassandra.threads.completed}\\\\s*%{integer:cassandra.threads.blocked}\\\\s*%{integer:cassandra.threads.all_time_blocked}|%{integer:cassandra.threads.active}\\\\s*%{integer:cassanadra.threads.pending})\",\"%{_prefix} %{integer:db.operations} operations were slow in the last %{integer:elapsed_time:scale(1000000)} msecs:\\\\n%{data}\",\"%{_prefix} %{data:msg}\"],\naliases: {\n\"cassandra_compaction_key\": \"%{_prefix} %{regex(\\\"Compacting\\\"):db.operation}.* %{_keyspace}\\\\/%{_table}:%{data:partition_key} \\\\(%{_bytes} bytes\\\\)\",\n\"cassandra_pool_cleaner\": \"%{_prefix} %{regex(\\\"Flushing\\\"):db.operation}.*\\\\(Keyspace='%{_keyspace}', ColumnFamily='%{_table}'\\\\) %{data}: %{_onheap_total}\\\\/%{_offheap_total}, live: %{_onheap_live}\\\\/%{_offheap_live}, flushing: %{_onheap_flush}\\\\/%{_offheap_flush}, this: %{_onheap_this}\\\\/%{_offheap_this}\",\n\"cassandra_pool_cleaner2\": \"%{_prefix} %{regex(\\\"Enqueuing\\\"):db.operation}.* of %{_keyspace}: %{_onheap_bytes}%{data} \\\\(%{_onheap_pct}%\\\\) on-heap, %{_offheap_bytes} \\\\(%{_offheap_pct}%\\\\).*\",\n\"cassandra_table_flush\": \"%{_prefix} %{regex(\\\"Writing\\\"):db.operation}.*-%{_keyspace}%{data}\\\\(%{number:cassandra.bytes:scale(1000000)}%{data}, %{integer:cassandra.ops} ops, %{_onheap_pct}%\\\\/%{_offheap_pct}.*\",\n\"cassandra_mem_flush\": \"%{_prefix} Completed %{regex(\\\"flushing\\\"):db.operation} %{_sstable} \\\\(%{number:cassandra.bytes_kb}KiB\\\\) for commitlog %{data:commitlog}\",\n\"cassandra_compaction\": \"%{_prefix}\\\\s+%{regex(\\\"Compacted\\\"):db.operation}.* to \\\\[%{_sstable}\\\\].\\\\s+%{notSpace:cassandra.bytes_in} bytes to %{notSpace:cassandra.bytes_out} \\\\(\\\\~%{integer:cassandra.percent_of_orig}% of original\\\\) in %{notSpace:cassandra.duration_ms}ms = %{number:cassandra.speed_mb}MB/s.\\\\s+%{notSpace:cassandra.pkeys_in} total partitions merged to %{notSpace:cassandra.pkeys_out}\\\\.\\\\s+Partition merge counts were %{data:cassandra.merge_cnt}\",\n\"cassandra_gc_format\": \"%{_prefix} G.* %{integer:duration:scale(1000000)}ms. %{data}: %{integer:cassandra.eden.orig_bytes} -\u003e %{integer:cassandra.eden.new_bytes}; %{data}: %{integer:cassandra.oldgen.orig_bytes} -\u003e %{integer:cassandra.oldgen.new_bytes};.*\",\n\"cassandra_thread_pending\": \"%{_prefix} %{word:cassandra.pool}\\\\s*(?\u003e%{integer:cassandra.cache_used}\\\\s*%{integer:cassandra.cache_size}\\\\s*all|%{integer:cassandra.threads.active}\\\\s*%{integer:cassandra.threads.pending}\\\\s*%{integer:cassandra.threads.completed}\\\\s*%{integer:cassandra.threads.blocked}\\\\s*%{integer:cassandra.threads.all_time_blocked}|%{integer:cassandra.threads.active}\\\\s*%{integer:cassanadra.threads.pending})\",\n\"cassandra_slow_statements\": \"%{_prefix} %{integer:db.operations} operations were slow in the last %{integer:elapsed_time:scale(1000000)} msecs:\\\\n%{data}\",\n\"cassandra_fallback_parser\": \"%{_prefix} %{data:msg}\",\n\"_level\": \"%{word:db.severity}\",\n\"_thread_name\": \"%{notSpace:logger.thread_name}\",\n\"_thread_id\": \"%{integer:logger.thread_id}\",\n\"_logger_name\": \"%{notSpace:logger.name}\",\n\"_table\": \"%{word:db.table}\",\n\"_sstable\": \"%{notSpace:cassandra.sstable}\",\n\"_bytes\": \"%{integer:cassandra.bytes}\",\n\"_keyspace\": \"%{word:cassandra.keyspace}\",\n\"_onheap_total\": \"%{number:cassandra.onheap.total}\",\n\"_onheap_live\": \"%{number:cassandra.onheap.live}\",\n\"_onheap_flush\": \"%{number:cassandra.onheap.flush}\",\n\"_onheap_this\": \"%{number:cassandra.onheap.this}\",\n\"_onheap_bytes\": \"%{integer:cassandra.onheap.bytes}\",\n\"_onheap_pct\": \"%{integer:cassandra.onheap.percent}\",\n\"_offheap_total\": \"%{number:cassandra.offheap.total}\",\n\"_offheap_live\": \"%{number:cassandra.offheap.live}\",\n\"_offheap_flush\": \"%{number:cassandra.offheap.flush}\",\n\"_offheap_this\": \"%{number:cassandra.offheap.this}\",\n\"_offheap_bytes\": \"%{integer:cassandra.offheap.bytes}\",\n\"_offheap_pct\": \"%{integer:cassandra.offheap.percent}\",\n\"_default_prefix\": \"%{_level}\\\\s+\\\\[(%{_thread_name}:%{_thread_id}|%{_thread_name})\\\\]\\\\s+%{date(\\\"yyyy-MM-dd HH:mm:ss,SSS\\\"):db.date}\\\\s+%{word:filename}.java:%{integer:lineno} -\",\n\"_suggested_prefix\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss\\\"):db.date} \\\\[(%{_thread_name}:%{_thread_id}|%{_thread_name})\\\\] %{_level} %{_logger_name}\\\\s+-\",\n\"_prefix\": \"(?\u003e%{_default_prefix}|%{_suggested_prefix})\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.cassandra.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.db.date) {\n.timestamp = .custom.db.date\n}\n'''\n\n[[transforms.processing.logs.pipelines.cassandra.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.db.severity) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[transforms.processing.logs.pipelines.apache_httpd]\nname = \"apache_httpd\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:httpd\"\n\n[[transforms.processing.logs.pipelines.apache_httpd.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_client_ip} %{_ident} %{_auth} \\\\[%{_date_access}\\\\] \\\"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\\\" %{_status_code} (?\u003e%{_bytes_written}|-)\",\"%{access.common} \\\"%{_referer}\\\" \\\"%{_user_agent}\\\"\"],\naliases: {\n\"access.common\": \"%{_client_ip} %{_ident} %{_auth} \\\\[%{_date_access}\\\\] \\\"(?\u003e%{_method} |)%{_url}(?\u003e %{_version}|)\\\" %{_status_code} (?\u003e%{_bytes_written}|-)\",\n\"access.combined\": \"%{access.common} \\\"%{_referer}\\\" \\\"%{_user_agent}\\\"\",\n\"_auth\": \"%{notSpace:http.auth:nullIf(\\\"-\\\")}\",\n\"_bytes_written\": \"%{integer:network.bytes_written}\",\n\"_client_ip\": \"%{ipOrHost:network.client.ip}\",\n\"_version\": \"HTTP\\\\/%{regex(\\\"\\\\\\\\d+\\\\\\\\.\\\\\\\\d+\\\"):http.version}\",\n\"_url\": \"%{notSpace:http.url}\",\n\"_ident\": \"%{notSpace:http.ident:nullIf(\\\"-\\\")}\",\n\"_user_agent\": \"%{regex(\\\"[^\\\\\\\\\\\\\\\"]*\\\"):http.useragent}\",\n\"_referer\": \"%{notSpace:http.referer}\",\n\"_status_code\": \"%{integer:http.status_code}\",\n\"_method\": \"%{word:http.method}\",\n\"_date_access\": \"%{date(\\\"dd/MMM/yyyy:HH:mm:ss Z\\\"):date_access}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.apache_httpd.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_user_agent(.custom.http.useragent); err == null) {\n  .custom.http.useragent_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.apache_httpd.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_url(.custom.http.url); err == null) {\n  .custom.http.url_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.apache_httpd.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.date_access) {\n.timestamp = .custom.date_access\n}\n'''\n\n[[transforms.processing.logs.pipelines.apache_httpd.transforms]]\ntype = \"remap\"\nsource = '''\nif match_datadog_query(., \"@http.status_code:[200 TO 299]\") {\n.custom.http.status_category = \"OK\"\n} else if match_datadog_query(., \"@http.status_code:[300 TO 399]\") {\n.custom.http.status_category = \"notice\"\n} else if match_datadog_query(., \"@http.status_code:[400 TO 499]\") {\n.custom.http.status_category = \"warning\"\n} else if match_datadog_query(., \"@http.status_code:[500 TO 599]\") {\n.custom.http.status_category = \"error\"\n}\n'''\n\n[[transforms.processing.logs.pipelines.apache_httpd.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.http.status_category) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[transforms.processing.logs.pipelines.azure_recovery_services]\nname = \"azure_recovery_services\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:azure.recoveryservices\"\n\n[[transforms.processing.logs.pipelines.azure_recovery_services.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.time) {\n.timestamp = .custom.time\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_recovery_services.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_recovery_services.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.category) {\n.custom.evt.category = .custom.category\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_recovery_services.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.operationName) {\n.custom.evt.name = .custom.operationName\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_recovery_services.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.resultType) {\n.custom.evt.outcome = .custom.resultType\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_recovery_services.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.callerIpAddress) {\n.custom.network.client.ip = .custom.callerIpAddress\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_recovery_services.transforms]]\ntype = \"remap\"\nsource = '''\nif (result, err = .custom.durationMs * 1000000; err == null) {\n  .custom.duration = result\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_recovery_services.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.identity.authorization.evidence.principalId) {\n.custom.usr.id = .custom.identity.authorization.evidence.principalId\n}\n'''\n\n[[transforms.processing.logs.pipelines.azure_recovery_services.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.properties.Entity_Name) {\n.custom.entity_name = .custom.properties.Entity_Name\n}\n'''\n\n[transforms.processing.logs.pipelines.c_]\nname = \"c_\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:csharp\"\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.logger) {\n.custom.logger.name = .custom.logger\n}\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.thread) {\n.custom.logger.thread_name = .custom.thread\n}\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.exception) {\n.custom.error.stack = .custom.exception\n} else if exists(.custom.stack_trace) {\n.custom.error.stack = .custom.stack_trace\n}\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .message,\npatterns: [\"%{_date} %{_status} \\\\[%{_thread_name}\\\\] %{_logger_name} %{_method}:%{_line} - %{data:message}((\\\\n|\\\\t)%{data:error.stack})?\",\"(%{_date}|%{_date_ms}) %{_status}\\\\s+%{data:message}((\\\\n|\\\\t)%{data:error.stack})?\",\"%{date(\\\"yyyy-MM-dd HH:mm:ss.SSS Z\\\"):date} \\\\[%{_status}\\\\] %{data}\",\"(%{date(\\\"yyyy-MM-dd HH:mm:ss.SSSS\\\"):date}|%{date(\\\"yyyy-MM-dd HH:mm:ss.SSS\\\"):date}|%{date(\\\"yyyy-MM-dd HH:mm:ss.SS\\\"):date}|%{date(\\\"yyyy-MM-dd HH:mm:ss.SSSSS\\\"):date})\\\\|%{_status}\\\\|%{notSpace:logger.name}\\\\|\\\\{%{data}\\\\}.*\",\"%{date(\\\"yyyy-MM-dd HH:mm:ss,SSS\\\"):date} \\\\[%{number}\\\\] %{_status}\\\\s+%{notSpace:logger.name} \\\\[%{notSpace}\\\\] \\\\{%{data}\\\\}.*\"],\naliases: {\n\"recommended_format\": \"%{_date} %{_status} \\\\[%{_thread_name}\\\\] %{_logger_name} %{_method}:%{_line} - %{data:message}((\\\\n|\\\\t)%{data:error.stack})?\",\n\"default_parser\": \"(%{_date}|%{_date_ms}) %{_status}\\\\s+%{data:message}((\\\\n|\\\\t)%{data:error.stack})?\",\n\"serilog_format\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss.SSS Z\\\"):date} \\\\[%{_status}\\\\] %{data}\",\n\"Nlog_format\": \"(%{date(\\\"yyyy-MM-dd HH:mm:ss.SSSS\\\"):date}|%{date(\\\"yyyy-MM-dd HH:mm:ss.SSS\\\"):date}|%{date(\\\"yyyy-MM-dd HH:mm:ss.SS\\\"):date}|%{date(\\\"yyyy-MM-dd HH:mm:ss.SSSSS\\\"):date})\\\\|%{_status}\\\\|%{notSpace:logger.name}\\\\|\\\\{%{data}\\\\}.*\",\n\"log4net_format\": \"%{date(\\\"yyyy-MM-dd HH:mm:ss,SSS\\\"):date} \\\\[%{number}\\\\] %{_status}\\\\s+%{notSpace:logger.name} \\\\[%{notSpace}\\\\] \\\\{%{data}\\\\}.*\",\n\"_date\": \"(%{date(\\\"yyyy-MM-dd HH:mm:ss.SSSS\\\"):date}|%{date(\\\"yyyy-MM-dd HH:mm:ss.SSS\\\"):date})\",\n\"_date_ms\": \"%{date(\\\"yyyy-MM-dd'T'HH:mm:ss.SSSZ\\\"):date}\",\n\"_status\": \"%{word:level}\",\n\"_thread_name\": \"%{notSpace:logger.thread_name}\",\n\"_logger_name\": \"%{notSpace:logger.name}\",\n\"_line\": \"%{integer:line}\",\n\"_method\": \"%{notSpace:method}\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.date) {\n.timestamp = .custom.date\n} else if exists(.custom.time) {\n.timestamp = .custom.time\n} else if exists(.custom.@t) {\n.timestamp = .custom.@t\n}\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\nstatus = string(.custom.level) ?? string(.custom.Level) ?? string(.custom.@l) ?? \"\"\nif status == \"\" {\n .status = 6\n} else {\nif starts_with(status, \"e\", case_sensitive: false) {\n    .status = 0\n} else if starts_with(status, \"a\", case_sensitive: false) {\n    .status = 1\n} else if starts_with(status, \"c\", case_sensitive: false) {\n    .status = 2\n} else if starts_with(status, \"e\", case_sensitive: false) {\n    .status = 3\n} else if starts_with(status, \"w\", case_sensitive: false) {\n    .status = 4\n} else if starts_with(status, \"n\", case_sensitive: false) {\n    .status = 5\n} else if starts_with(status, \"i\", case_sensitive: false) {\n    .status = 6\n} else if starts_with(status, \"d\", case_sensitive: false) {\n    .status = 7\n} else if starts_with(status, \"o\", case_sensitive: false) {\n    .status = 8\n}\n}\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\ncustom, err = parse_groks(value: .error.stack,\npatterns: [\"%{notSpace:error.kind}: %{data:error.message}(\\\\n|\\\\t).*\"],\naliases: {\n\"error_rule\": \"%{notSpace:error.kind}: %{data:error.message}(\\\\n|\\\\t).*\"\n\n})\n.custom, err = merge(.custom, custom)\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.trace_id) {\n.trace_id = .custom.dd.trace_id\n} else if exists(.custom.dd_trace_id) {\n.trace_id = .custom.dd_trace_id\n} else if exists(.custom.Properties.dd.trace_id) {\n.trace_id = .custom.Properties.dd.trace_id\n} else if exists(.custom.properties.dd.trace_id) {\n.trace_id = .custom.properties.dd.trace_id\n} else if exists(.custom.Properties.dd_trace_id) {\n.trace_id = .custom.Properties.dd_trace_id\n}\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.RenderedMessage) {\n.message = .custom.RenderedMessage\n} else if exists(.custom.@m) {\n.message = .custom.@m\n} else if exists(.custom.@mt) {\n.message = .custom.@mt\n} else if exists(.custom.message) {\n.message = .custom.message\n}\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.env) {\n.custom.env = .custom.dd.env\n} else if exists(.custom.dd_env) {\n.custom.env = .custom.dd_env\n} else if exists(.custom.Properties.dd.env) {\n.custom.env = .custom.Properties.dd.env\n} else if exists(.custom.properties.dd.env) {\n.custom.env = .custom.properties.dd.env\n} else if exists(.custom.Properties.dd_env) {\n.custom.env = .custom.Properties.dd_env\n}\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.version) {\n.custom.version = .custom.dd.version\n} else if exists(.custom.dd_version) {\n.custom.version = .custom.dd_version\n} else if exists(.custom.Properties.dd.version) {\n.custom.version = .custom.Properties.dd.version\n} else if exists(.custom.properties.dd.version) {\n.custom.version = .custom.properties.dd.version\n} else if exists(.custom.Properties.dd_version) {\n.custom.version = .custom.Properties.dd_version\n}\n'''\n\n[[transforms.processing.logs.pipelines.c_.transforms]]\ntype = \"remap\"\nsource = '''\nif exists(.custom.dd.service) {\n.service = .custom.dd.service\n} else if exists(.custom.dd_service) {\n.service = .custom.dd_service\n} else if exists(.custom.Properties.dd.service) {\n.service = .custom.Properties.dd.service\n} else if exists(.custom.properties.dd.service) {\n.service = .custom.properties.dd.service\n} else if exists(.custom.Properties.dd_service) {\n.service = .custom.Properties.dd_service\n}\n'''\n\n[transforms.processing.logs.pipelines.web_browser_logs]\nname = \"web_browser_logs\"\nfilter.type = \"datadog_search\"\nfilter.source = \"source:browser\"\n\n[[transforms.processing.logs.pipelines.web_browser_logs.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_url(.custom.http.url); err == null) {\n  .custom.http.url_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.web_browser_logs.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_user_agent(.custom.http.useragent); err == null) {\n  .custom.http.useragent_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.web_browser_logs.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_url(.custom.view.url); err == null) {\n  .custom.view.url_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.web_browser_logs.transforms]]\ntype = \"remap\"\nsource = '''\nif (details, err = parse_url(.custom.view.referrer); err == null) {\n  .custom.view.referrer_details = details\n}\n'''\n\n[[transforms.processing.logs.pipelines.web_browser_logs.transforms]]\ntype = \"remap\"\nsource = '''\n#TODO: geo-ip-parser\n'''\n\n##\n## Sinks\n##\n\n[sinks.prometheus]\ntype = \"prometheus_exporter\"\ninputs = [\"internal_metrics\"]\naddress = \"0.0.0.0:9090\"\n\n[sinks.blackhole]\ntype = \"blackhole\"\ninputs = [\"processing\"]\n"
            },
            "id": "soak/vector",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "vector",
                "namespace": "soak",
                "resource_version": "459",
                "uid": "e5e5b243-8403-40b4-968b-133c55099168"
              }
            ]
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kubernetes_namespace.soak"
          ]
        }
      ]
    },
    {
      "module": "module.vector",
      "mode": "managed",
      "type": "kubernetes_deployment",
      "name": "vector",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "id": "soak/vector",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 1,
                "labels": {
                  "app": "vector",
                  "type": "comparison"
                },
                "name": "vector",
                "namespace": "soak",
                "resource_version": "509",
                "uid": "347dc6d9-27e0-4d92-b5c4-706d5f21187d"
              }
            ],
            "spec": [
              {
                "min_ready_seconds": 0,
                "paused": false,
                "progress_deadline_seconds": 600,
                "replicas": "1",
                "revision_history_limit": 10,
                "selector": [
                  {
                    "match_expressions": [],
                    "match_labels": {
                      "app": "vector",
                      "type": "comparison"
                    }
                  }
                ],
                "strategy": [
                  {
                    "rolling_update": [
                      {
                        "max_surge": "25%",
                        "max_unavailable": "25%"
                      }
                    ],
                    "type": "RollingUpdate"
                  }
                ],
                "template": [
                  {
                    "metadata": [
                      {
                        "annotations": {
                          "prometheus.io/path": "/metrics",
                          "prometheus.io/port": "9090",
                          "prometheus.io/scrape": "true"
                        },
                        "generate_name": "",
                        "generation": 0,
                        "labels": {
                          "app": "vector",
                          "type": "comparison"
                        },
                        "name": "",
                        "namespace": "",
                        "resource_version": "",
                        "uid": ""
                      }
                    ],
                    "spec": [
                      {
                        "active_deadline_seconds": 0,
                        "affinity": [],
                        "automount_service_account_token": false,
                        "container": [
                          {
                            "args": null,
                            "command": null,
                            "env": [],
                            "env_from": [],
                            "image": "vector:6a71553d1e2d49501f03e40ce78090934fcfab13",
                            "image_pull_policy": "IfNotPresent",
                            "lifecycle": [],
                            "liveness_probe": [
                              {
                                "exec": [],
                                "failure_threshold": 3,
                                "http_get": [
                                  {
                                    "host": "",
                                    "http_header": [],
                                    "path": "/metrics",
                                    "port": "9090",
                                    "scheme": "HTTP"
                                  }
                                ],
                                "initial_delay_seconds": 0,
                                "period_seconds": 10,
                                "success_threshold": 1,
                                "tcp_socket": [],
                                "timeout_seconds": 1
                              }
                            ],
                            "name": "vector",
                            "port": [
                              {
                                "container_port": 8282,
                                "host_ip": "",
                                "host_port": 0,
                                "name": "source",
                                "protocol": "TCP"
                              },
                              {
                                "container_port": 9090,
                                "host_ip": "",
                                "host_port": 0,
                                "name": "prom-export",
                                "protocol": "TCP"
                              }
                            ],
                            "readiness_probe": [],
                            "resources": [
                              {
                                "limits": {
                                  "cpu": "4"
                                },
                                "requests": {
                                  "cpu": "4",
                                  "memory": "512Mi"
                                }
                              }
                            ],
                            "security_context": [],
                            "startup_probe": [],
                            "stdin": false,
                            "stdin_once": false,
                            "termination_message_path": "/dev/termination-log",
                            "termination_message_policy": "File",
                            "tty": false,
                            "volume_mount": [
                              {
                                "mount_path": "/var/lib/vector",
                                "mount_propagation": "None",
                                "name": "var-lib-vector",
                                "read_only": false,
                                "sub_path": ""
                              },
                              {
                                "mount_path": "/etc/vector",
                                "mount_propagation": "None",
                                "name": "etc-vector",
                                "read_only": true,
                                "sub_path": ""
                              }
                            ],
                            "working_dir": ""
                          }
                        ],
                        "dns_config": [],
                        "dns_policy": "ClusterFirst",
                        "enable_service_links": true,
                        "host_aliases": [],
                        "host_ipc": false,
                        "host_network": false,
                        "host_pid": false,
                        "hostname": "",
                        "image_pull_secrets": [],
                        "init_container": [],
                        "node_name": "",
                        "node_selector": null,
                        "priority_class_name": "",
                        "readiness_gate": [],
                        "restart_policy": "Always",
                        "security_context": [],
                        "service_account_name": "",
                        "share_process_namespace": false,
                        "subdomain": "",
                        "termination_grace_period_seconds": 30,
                        "toleration": [],
                        "topology_spread_constraint": [],
                        "volume": [
                          {
                            "aws_elastic_block_store": [],
                            "azure_disk": [],
                            "azure_file": [],
                            "ceph_fs": [],
                            "cinder": [],
                            "config_map": [],
                            "csi": [],
                            "downward_api": [],
                            "empty_dir": [
                              {
                                "medium": "",
                                "size_limit": ""
                              }
                            ],
                            "fc": [],
                            "flex_volume": [],
                            "flocker": [],
                            "gce_persistent_disk": [],
                            "git_repo": [],
                            "glusterfs": [],
                            "host_path": [],
                            "iscsi": [],
                            "local": [],
                            "name": "var-lib-vector",
                            "nfs": [],
                            "persistent_volume_claim": [],
                            "photon_persistent_disk": [],
                            "projected": [],
                            "quobyte": [],
                            "rbd": [],
                            "secret": [],
                            "vsphere_volume": []
                          },
                          {
                            "aws_elastic_block_store": [],
                            "azure_disk": [],
                            "azure_file": [],
                            "ceph_fs": [],
                            "cinder": [],
                            "config_map": [
                              {
                                "default_mode": "0644",
                                "items": [],
                                "name": "vector",
                                "optional": false
                              }
                            ],
                            "csi": [],
                            "downward_api": [],
                            "empty_dir": [],
                            "fc": [],
                            "flex_volume": [],
                            "flocker": [],
                            "gce_persistent_disk": [],
                            "git_repo": [],
                            "glusterfs": [],
                            "host_path": [],
                            "iscsi": [],
                            "local": [],
                            "name": "etc-vector",
                            "nfs": [],
                            "persistent_volume_claim": [],
                            "photon_persistent_disk": [],
                            "projected": [],
                            "quobyte": [],
                            "rbd": [],
                            "secret": [],
                            "vsphere_volume": []
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            ],
            "timeouts": null,
            "wait_for_rollout": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6NjAwMDAwMDAwMDAwLCJ1cGRhdGUiOjYwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9",
          "dependencies": [
            "kubernetes_namespace.soak",
            "module.vector.kubernetes_config_map.vector"
          ]
        }
      ]
    },
    {
      "module": "module.vector",
      "mode": "managed",
      "type": "kubernetes_service",
      "name": "vector",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "id": "soak/vector",
            "metadata": [
              {
                "annotations": null,
                "generate_name": "",
                "generation": 0,
                "labels": null,
                "name": "vector",
                "namespace": "soak",
                "resource_version": "461",
                "uid": "974c3c1a-618d-4b26-b1f4-95039dc5a5c1"
              }
            ],
            "spec": [
              {
                "cluster_ip": "10.97.37.57",
                "external_ips": null,
                "external_name": "",
                "external_traffic_policy": "",
                "health_check_node_port": 0,
                "load_balancer_ip": "",
                "load_balancer_source_ranges": null,
                "port": [
                  {
                    "name": "source",
                    "node_port": 0,
                    "port": 8282,
                    "protocol": "TCP",
                    "target_port": "8282"
                  },
                  {
                    "name": "prom-export",
                    "node_port": 0,
                    "port": 9090,
                    "protocol": "TCP",
                    "target_port": "9090"
                  }
                ],
                "publish_not_ready_addresses": false,
                "selector": {
                  "app": "vector",
                  "type": "comparison"
                },
                "session_affinity": "ClientIP",
                "type": "ClusterIP"
              }
            ],
            "status": [
              {
                "load_balancer": [
                  {
                    "ingress": []
                  }
                ]
              }
            ],
            "timeouts": null,
            "wait_for_load_balancer": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDB9LCJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "kubernetes_namespace.soak"
          ]
        }
      ]
    }
  ]
}
